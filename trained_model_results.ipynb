{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看准确率\n",
    "net_to_save_dir = \"Saved_Models\"\n",
    "saved_model_name = 'Best_model.t7'\n",
    "fold=2\n",
    "# enabled_nets = [\"ACNN\", \"ACCNN\", \"AlexNet\"]\n",
    "enabled_nets = [\"ACCNN\"]\n",
    "enabled_datasets = [\"JAFFE\", \"CK+48\", \"CK+\", \"FER2013\"]\n",
    "for net in enabled_nets:\n",
    "    for dataset in enabled_datasets:\n",
    "        net_to_save_path = os.path.join(net_to_save_dir, dataset + '_' + net + \"_\" + str(fold))\n",
    "        checkpoint = torch.load(os.path.join(net_to_save_path, saved_model_name))\n",
    "        best_acc = checkpoint['best_test_acc']\n",
    "        best_acc_epoch = checkpoint['best_test_acc_epoch']\n",
    "        currect_map = checkpoint['correct_map']\n",
    "        print(\"---------------net: %s, dataset: %s---------------\" % (net, dataset))\n",
    "        print(\"best_acc:\", best_acc)\n",
    "        print(\"best_acc_epoch:\", best_acc_epoch)\n",
    "        print(\"currect_map:\", currect_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------net: ACCNN, dataset: JAFFE---------------\n",
      "best_acc: 57\n",
      "best_acc_epoch: 232\n",
      "currect_map: [3, 2, 0, 3, 3, 0, 1]\n",
      "---------------net: ACCNN, dataset: JAFFE---------------\n",
      "best_acc: 14\n",
      "best_acc_epoch: 0\n",
      "currect_map: [0, 0, 0, 0, 3, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 对比脸定位部剪裁前后的训练结果\n",
    "net_to_save_dir = \"Saved_Models\"\n",
    "saved_model_name = 'Best_model.t7'\n",
    "fold=[2, 3]\n",
    "# enabled_nets = [\"ACNN\", \"ACCNN\", \"AlexNet\"]\n",
    "enabled_nets = [\"ACCNN\"]\n",
    "enabled_datasets = [\"JAFFE\"]\n",
    "for f in fold:\n",
    "    for net in enabled_nets:\n",
    "        for dataset in enabled_datasets:\n",
    "            net_to_save_path = os.path.join(net_to_save_dir, dataset + '_' + net + \"_\" + str(f))\n",
    "            checkpoint = torch.load(os.path.join(net_to_save_path, saved_model_name))\n",
    "            best_acc = checkpoint['best_test_acc']\n",
    "            best_acc_epoch = checkpoint['best_test_acc_epoch']\n",
    "            currect_map = checkpoint['correct_map']\n",
    "            print(\"---------------net: %s, dataset: %s---------------\" % (net, dataset))\n",
    "            print(\"best_acc:\", best_acc)\n",
    "            print(\"best_acc_epoch:\", best_acc_epoch)\n",
    "            print(\"currect_map:\", currect_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.ACNN import ACNN\n",
    "from networks.ACCNN import ACCNN\n",
    "from networks.AlexNet import AlexNet\n",
    "from dal.CKPlus48_DataSet import CKPlus48\n",
    "from dal.FER2013_DataSet import FER2013\n",
    "from dal.JAFFE_DataSet import JAFFE\n",
    "import transforms.transforms as transforms\n",
    "from utils.utils import draw_img\n",
    "from PIL import Image\n",
    "from math import ceil, floor\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置信息\n",
    "use_cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "net_name, n_classes = 'ACCNN', 7\n",
    "\n",
    "if net_name == \"ACNN\":\n",
    "    net = ACNN(n_classes=n_classes).to(DEVICE)\n",
    "elif net_name == \"ACCNN\":\n",
    "    net = ACCNN(n_classes=n_classes).to(DEVICE)\n",
    "elif net_name == \"AlexNet\":\n",
    "    net = AlexNet(n_classes=n_classes).to(DEVICE)\n",
    "input_img_size = net.input_size\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(input_img_size),  # 缩放将图片的最小边缩放为 input_img_size，因此如果输入是费正方形的，那么输出也不是正方形的\n",
    "    transforms.RandomCrop(input_img_size),  # 用于将非正方形的图片进行处理\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_img_size = int(input_img_size * 1.1)  # 测试时，图片resize大小\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(test_img_size),\n",
    "    transforms.TenCrop(input_img_size),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "])\n",
    "dataset = 'CK+'\n",
    "target_type='ls'\n",
    "if dataset == \"JAFFE\":\n",
    "    test_data = JAFFE(is_train=False, transform=transform_test, target_type=target_type)\n",
    "elif dataset == \"CK+48\":\n",
    "    test_data = CKPlus48(is_train=False, transform=transform_test, target_type=target_type)\n",
    "elif dataset == \"CK+\":\n",
    "    test_data = CKPlus48(is_train=False, transform=transform_test, target_type=target_type, img_dir_pre_path=\"data/CK+\")\n",
    "elif dataset == \"FER2013\":\n",
    "    test_data = FER2013(is_train=False, private_test=True, transform=transform_test, target_type=target_type)\n",
    "else:\n",
    "    assert(\"opt.dataset should be in %s, but got %s\" % (enabled_datasets, dataset))\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# 获取model\n",
    "net_to_save_path = os.path.join(net_to_save_dir, dataset + '_' + net_name + \"_\" + str(fold))\n",
    "print(\"get net parameters from:\", net_to_save_path)\n",
    "checkpoint = torch.load(os.path.join(net_to_save_path, saved_model_name))\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "print(\"---------------net: %s, dataset: %s---------------\" % (net_name, dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取数据\n",
    "inputs, targets = next(iter(test_loader))\n",
    "# print(inputs.shape, targets)\n",
    "# input = inputs[0][0][0]\n",
    "# print(input.shape)\n",
    "# draw_img(input)\n",
    "\n",
    "bs, ncrops, c, h, w = np.shape(inputs)\n",
    "inputs = inputs.view(-1, c, h, w)\n",
    "if use_cuda:\n",
    "    inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "inputs, targets = Variable(inputs), Variable(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_features_of_layer(layer_number=-1, blank_size = 2, img_save_dir = \"Saved_Virtualizations\", img_save_name = \"default\"):\n",
    "    '''\n",
    "    绘制特征层的输出情况，layer_number=-1表示绘制最后一层\n",
    "    '''\n",
    "    # 绑定并测试\n",
    "    features_hook = []\n",
    "    def get_features_hook(self,input,output):\n",
    "        features_hook.append(input)\n",
    "\n",
    "    if layer_number >= 0:\n",
    "        handler = net.features[layer_number].register_forward_hook(get_features_hook)\n",
    "    else:\n",
    "        handler = net.features[-1].register_forward_hook(get_features_hook)\n",
    "    with torch.no_grad():\n",
    "        outputs = net(inputs)\n",
    "    handler.remove()\n",
    "\n",
    "    # 可视化展示\n",
    "    images = np.array(features_hook[0][0].cpu())\n",
    "#     print(images.shape)\n",
    "    for i in range(len(images)):\n",
    "        print(\"-----------img %s layer %s------------\" % (str(i), str(layer_number)))\n",
    "        image = images[i]\n",
    "#         print(\"image shape:\", image.shape)\n",
    "        image_shape = image.shape\n",
    "        col_num = int(ceil(image_shape[0] ** 0.5))\n",
    "        row_num = int(ceil(image_shape[0] / col_num))\n",
    "        height =  row_num * image_shape[1]\n",
    "        width =  col_num * image_shape[2]\n",
    "#         print(col_num, row_num, height, width)\n",
    "        img_arr = np.array([[0.5 for _ in range(width+(col_num-1)*blank_size)]for _ in range(height+(row_num-1)*blank_size)])\n",
    "        for j in range(len(image)):\n",
    "            start_row_index, start_col_index =  (j//col_num)*(blank_size+image_shape[1]), (j%col_num)*(blank_size+image_shape[2])\n",
    "            for row_pixel_index in range(image_shape[1]):\n",
    "                for col_pixel_index in range(image_shape[2]):\n",
    "                    img_arr[start_row_index+row_pixel_index][start_col_index+col_pixel_index] = image[j][row_pixel_index][col_pixel_index]\n",
    "        img = Image.fromarray(img_arr)\n",
    "        if not os.path.exists(img_save_dir):\n",
    "            os.mkdir(img_save_dir)\n",
    "        draw_img(img, os.path.join(img_save_dir, img_save_name+\"_of_img_\"+str(i)))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net.features)\n",
    "feature_indexes = [0,3,6,9,-1]\n",
    "for i in range(len(feature_indexes)):\n",
    "    idx = feature_indexes[i] \n",
    "#     draw_features_of_layer(i, img_save_name=\"feature_layer_\"+str(i))\n",
    "#     print(net.features[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in net.named_modules():\n",
    "    if isinstance(layer[1],nn.Conv2d):\n",
    "         print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_features_of_net(net, img_name_pre = \"\", blank_size = 2, img_save_dir = \"Saved_Virtualizations\"):\n",
    "    '''\n",
    "    绘制网络所有的特征层的输出情况\n",
    "    '''\n",
    "    # 绑定并测试\n",
    "    features_hook = []\n",
    "    def get_features_hook(self,input,output):\n",
    "        features_hook.append(input)\n",
    "    handlers = []\n",
    "    for layer in net.named_modules():\n",
    "        if isinstance(layer[1],nn.Conv2d):\n",
    "            handlers.append(layer[1].register_forward_hook(get_features_hook))\n",
    "    with torch.no_grad():\n",
    "        outputs = net(inputs)\n",
    "        features_hook.append(net.features_out)\n",
    "    for handler in handlers:\n",
    "        handler.remove()\n",
    "\n",
    "    # 可视化展示\n",
    "    for layer_number in range(len(features_hook)):\n",
    "        images = np.array(features_hook[layer_number][0].cpu())\n",
    "#         print(images.shape)\n",
    "        img_save_name = img_name_pre + \"_feature_layer_\" + str(layer_number)\n",
    "        for i in range(len(images)):\n",
    "#             print(\"-----------img %s------------\" % str(i))\n",
    "            image = images[i]\n",
    "#             print(\"image shape:\", image.shape)\n",
    "            image_shape = image.shape\n",
    "            col_num = int(ceil(image_shape[0] ** 0.5))\n",
    "            row_num = int(ceil(image_shape[0] / col_num))\n",
    "            height =  row_num * image_shape[1]\n",
    "            width =  col_num * image_shape[2]\n",
    "#             print(col_num, row_num, height, width)\n",
    "            img_arr = np.array([[0.5 for _ in range(width+(col_num-1)*blank_size)]for _ in range(height+(row_num-1)*blank_size)])\n",
    "            for j in range(len(image)):\n",
    "                start_row_index, start_col_index =  (j//col_num)*(blank_size+image_shape[1]), (j%col_num)*(blank_size+image_shape[2])\n",
    "                for row_pixel_index in range(image_shape[1]):\n",
    "                    for col_pixel_index in range(image_shape[2]):\n",
    "                        img_arr[start_row_index+row_pixel_index][start_col_index+col_pixel_index] = image[j][row_pixel_index][col_pixel_index]\n",
    "            img = Image.fromarray(img_arr)\n",
    "            if not os.path.exists(img_save_dir):\n",
    "                os.mkdir(img_save_dir)\n",
    "            draw_img(img, os.path.join(img_save_dir, img_save_name+\"_of_img_\"+str(i)))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_features_of_net(net, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_weights_of_net(net, img_name_pre = \"\", blank_size = 2, img_save_dir = \"Saved_Virtualizations\"):\n",
    "    layer_number = 0\n",
    "    stat_dict = net.state_dict()\n",
    "    for dic in stat_dict.keys():\n",
    "        dic_splited = dic.split(\".\")\n",
    "        if dic_splited[0] == 'features' and dic_splited[2] == 'weight':\n",
    "            img_save_name = img_name_pre + \"_weight_layer_\" + str(layer_number)\n",
    "            weights = stat_dict[dic]\n",
    "#             print(dic, weights)\n",
    "            out_channel_num = len(weights)\n",
    "            in_channel_num = len(weights[0])\n",
    "            kernel_height = len(weights[0][0])\n",
    "            kernel_width = len(weights[0][0][0])\n",
    "            img_arr = np.array([[0.5 for _ in range(kernel_width*in_channel_num+(in_channel_num-1)*blank_size)]for _ in range(kernel_height*out_channel_num+(out_channel_num-1)*blank_size)])\n",
    "#             print(img_arr.shape)\n",
    "            for out_channel_number in range(out_channel_num):\n",
    "                for in_channel_number in range(in_channel_num):\n",
    "                    start_row_index, start_col_index = (out_channel_number)*(blank_size+kernel_height), (in_channel_number)*(blank_size+kernel_width)\n",
    "                    kernel = weights[out_channel_number][in_channel_number]\n",
    "#                     print(kernel.shape)\n",
    "                    for row_pixel_index in range(kernel.shape[0]):\n",
    "                        for col_pixel_index in range(kernel.shape[1]):\n",
    "                            img_arr[start_row_index+row_pixel_index][start_col_index+col_pixel_index] = kernel[row_pixel_index][col_pixel_index]\n",
    "            img = Image.fromarray(img_arr)\n",
    "            if not os.path.exists(img_save_dir):\n",
    "                os.mkdir(img_save_dir)\n",
    "            draw_img(img, os.path.join(img_save_dir, img_save_name))\n",
    "            layer_number += 1\n",
    "draw_weights_of_net(net.cpu(), 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下部分用于测试训练完毕后的使用代码\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "sys.path.append(\"..\")\n",
    "from networks.ACCNN import ACCNN\n",
    "import transforms.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parameters...\n",
      "Loading parameters over!\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = ACCNN(7, True).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1397, 0.0186, 0.1559, 0.0383, 0.4064, 0.0089, 0.2322],\n",
      "        [0.1403, 0.0134, 0.1791, 0.1949, 0.3195, 0.0480, 0.1046],\n",
      "        [0.1059, 0.0160, 0.3123, 0.1040, 0.2470, 0.1073, 0.1075],\n",
      "        [0.1074, 0.0110, 0.1622, 0.1667, 0.2656, 0.0605, 0.2265],\n",
      "        [0.0262, 0.0044, 0.0348, 0.0122, 0.2909, 0.0029, 0.6285],\n",
      "        [0.0610, 0.0081, 0.0860, 0.1612, 0.2853, 0.0106, 0.3878],\n",
      "        [0.0480, 0.0034, 0.1019, 0.3117, 0.1733, 0.0961, 0.2657],\n",
      "        [0.1149, 0.0129, 0.1465, 0.0596, 0.2909, 0.0242, 0.3511],\n",
      "        [0.0791, 0.0154, 0.3402, 0.0299, 0.3361, 0.0864, 0.1129],\n",
      "        [0.0495, 0.0042, 0.0517, 0.0325, 0.1549, 0.0130, 0.6942]],\n",
      "       device='cuda:0') tensor([[0.0872, 0.0108, 0.1571, 0.1111, 0.2770, 0.0458, 0.3111]],\n",
      "       device='cuda:0')\n",
      "中性\n"
     ]
    }
   ],
   "source": [
    "# img_path = 'data/CK+/sadness/S011_002_00000020.png'\n",
    "img_path = 'data/CK+/sadness/S501_006_00000039.png'\n",
    "img = Image.open(img_path)\n",
    "img = img.convert(\"L\")\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(int(model.input_size*1.1)),\n",
    "    transforms.TenCrop(model.input_size),\n",
    "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "])\n",
    "inputs = transform_test(img)\n",
    "bs = 1\n",
    "ncrops, c, h, w = np.shape(inputs)\n",
    "with torch.no_grad():\n",
    "    inputs = inputs.view(-1, c, h, w)\n",
    "    if use_cuda:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "    inputs = Variable(inputs)\n",
    "    outputs = model(inputs)\n",
    "    outputs_avg = outputs.view(bs, ncrops, -1).mean(1)  # avg over crops\n",
    "    print(outputs, outputs_avg)\n",
    "    _, predicted = torch.max(outputs_avg.data, 1)\n",
    "    print(model.output_map[predicted.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
