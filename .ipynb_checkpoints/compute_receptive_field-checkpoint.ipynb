{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "'''\n",
    "假设输入为 W*W 大小的图片\n",
    "核 Kernal = F*F\n",
    "步长 Stride = S\n",
    "填充 padding = P\n",
    "输出图片的大小为 N*N  N = (W-F+2P)/S + 1\n",
    "                    W = (N-1)*S-2P+F\n",
    "感受野\n",
    "RF = 1 #待计算的feature map上的感受野大小\n",
    "for layer in （top layer To down layer）:\n",
    "    RF = ((RF - 1)* stride) + fsize  # 此处padding区域不考虑，其他和上述公式相同，只是RF刚开始变成1\n",
    "                    \n",
    "论文：120*120 crop->96*96 as inputs\n",
    "\n",
    "'''\n",
    "\n",
    "class ACCNN(nn.Module):\n",
    "    '''ACCNN 自己创建的神经网络，用于识别面部表情\n",
    "\n",
    "        n_class 表示输出的分类数\n",
    "        pre_trained 表示是否加载训练好的网络\n",
    "        root_pre_path 表示执行目录相对于项目目录的路径（用于debug）\n",
    "        dataset 表示预加载使用的模型参数训练自哪个数据集\n",
    "        fold 表示存储的文件序号\n",
    "        virtualize 表示是否进行可视化\n",
    "        using_fl 表示是否为根据face landmarks进行识别\n",
    "    '''\n",
    "    def __init__(self, n_classes=7, pre_trained=False, root_pre_path='', dataset='FER2013', fold=5, virtualize=False,\n",
    "                 using_fl=False):\n",
    "        # nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
    "        super(ACCNN, self).__init__()\n",
    "        self.input_size = 96\n",
    "        # x size [BATCHSIZE, 1, 120, 120]\n",
    "        # 测试论文\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5),   # 64, 92, 92\n",
    "            nn.ReLU(inplace=True),  # 使用nn.ReLU(inplace = True) 能将激活函数ReLU的输出直接覆盖保存于模型的输入之中，节省不少显存\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5),   # 64, 88, 88\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),      # 64, 44, 44\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5),  # 64, 40, 40\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5),  # 64, 36, 36\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=1),      # 64, 18, 18\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64 * 18 * 18, 64),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(64, n_classes),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Softmax(1),\n",
    "        )\n",
    "        # 3 # 25\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=64, kernel_size=5, stride=1),  # 64, 92, 92\n",
    "#             nn.ReLU(inplace=True),  # 使用nn.ReLU(inplace = True) 能将激活函数ReLU的输出直接覆盖保存于模型的输入之中，节省不少显存\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1),  # 64, 88, 88\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1),  # 64, 84, 84\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2),  # 64, 42, 42\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1),  # 64, 19, 19\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1),  # 64, 19, 19\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2),  # 64, 9, 9\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),  # 64, 9, 9\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),  # 64, 9, 9\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2),  # 64, 4, 4\n",
    "#         )\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             # nn.ReLU(inplace=True),\n",
    "#             nn.Linear(64 * 4 * 4, 512),\n",
    "#             nn.Dropout(p=0.6),\n",
    "#             # nn.ReLU(inplace=True),\n",
    "#             nn.Linear(512, n_classes),\n",
    "#             nn.Dropout(p=0.6),\n",
    "#             nn.Softmax(1),\n",
    "#         )\n",
    "        self.dataset = dataset\n",
    "        self.fold = fold\n",
    "        self.virtualize = virtualize\n",
    "        self.using_fl = using_fl\n",
    "        self.features_out = []\n",
    "        self.best_acc = 0.\n",
    "        self.best_acc_epoch = -1\n",
    "        if dataset == \"CK+\" or dataset == \"CK+48\":\n",
    "            self.output_map = {0:'生气', 1:'蔑视', 2:'恶心', 3:'害怕', 4:'开心', 5:'悲伤', 6:'惊讶'}\n",
    "        elif dataset == 'FER2013':\n",
    "            self.output_map = {0:'生气', 1:'恶心', 2:'害怕', 3:'开心', 4:'悲伤', 5:'惊讶', 6:'中性'}\n",
    "        elif dataset == 'JAFFE':\n",
    "            self.output_map = {0:'中性', 1:'开心', 2:'悲伤', 3:'惊讶', 4:'生气', 5:'恶心', 6:'害怕'}\n",
    "        else:\n",
    "            assert 'dataset error: should be in [\"JAFFE\", \"CK+48\", \"CK+\", \"FER2013\"]'\n",
    "            self.output_map = {}\n",
    "        if pre_trained:\n",
    "            save_model_dir_name = 'Saved_Models'\n",
    "            if self.using_fl:\n",
    "                saved_model_name = \"Best_model_fl.t7\"\n",
    "            else:\n",
    "                saved_model_name = 'Best_model.t7'\n",
    "            net_saved_path = os.path.join(root_pre_path, save_model_dir_name, str(fold), dataset + '_ACCNN_' + str(fold))\n",
    "            assert os.path.isdir(net_saved_path), 'Error: no checkpoint directory found!'\n",
    "            parameters_file_path = os.path.join(net_saved_path, saved_model_name)\n",
    "            print(\"Loading parameters from \", parameters_file_path)\n",
    "            checkpoint = torch.load(parameters_file_path)\n",
    "            self.load_state_dict(checkpoint['net'])\n",
    "            self.best_acc = checkpoint['best_test_acc']\n",
    "            self.best_acc_epoch = checkpoint['best_test_acc_epoch']\n",
    "            print(\"Loading parameters over!\")\n",
    "            print(\"Parameters are trained from %s(epoch %d) with test_acc: %3.f\"\n",
    "                  % (dataset, self.best_acc_epoch, self.best_acc))\n",
    "        else:\n",
    "            print('Initializing ACCNN weights...')\n",
    "            self._initialize_weights()\n",
    "        print('Init ACCNN model over!')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = self.features(x)\n",
    "        # print(x.size())\n",
    "        if self.virtualize:\n",
    "            self.features_out.append(x.clone())\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        # print(x.size())\n",
    "        x = self.classifier(x)\n",
    "        # print(x.size())\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "    def clean_features_out(self):\n",
    "        self.features_out = []\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for layer in self.named_modules():\n",
    "            if isinstance(layer[1], nn.Conv2d):\n",
    "                n = layer[1].kernel_size[0] * layer[1].kernel_size[1] * layer[1].out_channels\n",
    "                layer[1].weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if layer[1].bias is not None:\n",
    "                    layer[1].bias.data.zero_()\n",
    "            elif isinstance(layer[1], nn.Linear):\n",
    "                layer[1].weight.data.normal_(0, 0.01)\n",
    "                layer[1].bias.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ACCNN weights...\n",
      "Init ACCNN model over!\n",
      "ACCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (10): ReLU(inplace)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): Dropout(p=0.6)\n",
      "    (2): Linear(in_features=512, out_features=7, bias=True)\n",
      "    (3): Dropout(p=0.6)\n",
      "    (4): Softmax()\n",
      "  )\n",
      ")\n",
      "features.0.weight : torch.Size([64, 1, 5, 5])\n",
      "1600\n",
      "features.0.bias : torch.Size([64])\n",
      "64\n",
      "features.2.weight : torch.Size([64, 64, 5, 5])\n",
      "102400\n",
      "features.2.bias : torch.Size([64])\n",
      "64\n",
      "features.4.weight : torch.Size([64, 64, 5, 5])\n",
      "102400\n",
      "features.4.bias : torch.Size([64])\n",
      "64\n",
      "features.7.weight : torch.Size([64, 64, 5, 5])\n",
      "102400\n",
      "features.7.bias : torch.Size([64])\n",
      "64\n",
      "features.9.weight : torch.Size([64, 64, 5, 5])\n",
      "102400\n",
      "features.9.bias : torch.Size([64])\n",
      "64\n",
      "features.12.weight : torch.Size([64, 64, 3, 3])\n",
      "36864\n",
      "features.12.bias : torch.Size([64])\n",
      "64\n",
      "features.14.weight : torch.Size([64, 64, 3, 3])\n",
      "36864\n",
      "features.14.bias : torch.Size([64])\n",
      "64\n",
      "classifier.0.weight : torch.Size([512, 1024])\n",
      "524288\n",
      "classifier.0.bias : torch.Size([512])\n",
      "512\n",
      "classifier.2.weight : torch.Size([7, 512])\n",
      "3584\n",
      "classifier.2.bias : torch.Size([7])\n",
      "7\n",
      "num_of_parameters_of_net:  1013767\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import num_of_parameters_of_net\n",
    "n_classes = 7\n",
    "net = ACCNN(n_classes=n_classes, root_pre_path='..', pre_trained=False)\n",
    "print(net)\n",
    "print(\"num_of_parameters_of_net: \", num_of_parameters_of_net(net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [kernel_size, stride, padding]\n",
    "net_struct = {'ACCNN0': {'net':[[5,1,0],[5,1,0],[2,2,0],[5,1,0],[5,1,0],[2,2,0]],\n",
    "                        'name':['conv1','conv2','pool1','conv4','conv5','pool2']},\n",
    "              'ACCNN1': {'net':[[9,1,0],[9,1,0],[5,1,0],[2,2,0],[5,1,0],[5,1,0],[2,2,0]],\n",
    "                        'name':['conv1','conv2','conv3','pool1','conv4','conv5','pool2']},\n",
    "              'ACCNN2': {'net':[[9,1,0],[5,1,0],[5,2,0],[2,2,0],[5,1,0],[5,1,0],[2,2,0]],\n",
    "                        'name':['conv1','conv2','conv3','pool1','conv4','conv5','pool2']},\n",
    "              'ACCNN3': {'net':[[9,1,0],[5,2,0],[5,1,0],[2,2,0],[5,1,2],[5,1,2],[2,2,0],[3,1,1],[3,1,1],[2,2,0]],\n",
    "                        'name':['conv1','conv2','conv3','pool1','conv4','conv5','pool2','conv6','conv7','pool3']}}\n",
    "imsize = net.input_size\n",
    "\n",
    "def outFromIn(isz, net, layernum):\n",
    "    totstride = 1\n",
    "    insize = isz\n",
    "    for layer in range(layernum):\n",
    "        fsize, stride, pad = net[layer]\n",
    "        outsize = (insize - fsize + 2*pad) / stride + 1\n",
    "        insize = outsize\n",
    "        totstride = totstride * stride\n",
    "    return outsize, totstride\n",
    "\n",
    "def inFromOut(net, layernum):\n",
    "    RF = 1\n",
    "    for layer in reversed(range(layernum)):\n",
    "        fsize, stride, pad = net[layer]\n",
    "        RF = ((RF -1)* stride) + fsize\n",
    "    return RF\n",
    "\n",
    "def main():\n",
    "    print(\"layer output sizes given image = %dx%d\" % (imsize, imsize))\n",
    "    \n",
    "    for net in net_struct.keys():\n",
    "        print('************net structrue name is %s**************'% net)\n",
    "        for i in range(len(net_struct[net]['net'])):\n",
    "            p = outFromIn(imsize,net_struct[net]['net'], i+1)\n",
    "            rf = inFromOut(net_struct[net]['net'], i+1)\n",
    "            print(\"Layer Name = %s, Output size = %3d, Stride = % 3d, RF size = %3d\" % (net_struct[net]['name'][i], p[0], p[1], rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer output sizes given image = 96x96\n",
      "************net structrue name is ACCNN0**************\n",
      "Layer Name = conv1, Output size =  92, Stride =   1, RF size =   5\n",
      "Layer Name = conv2, Output size =  88, Stride =   1, RF size =   9\n",
      "Layer Name = pool1, Output size =  44, Stride =   2, RF size =  10\n",
      "Layer Name = conv4, Output size =  40, Stride =   2, RF size =  18\n",
      "Layer Name = conv5, Output size =  36, Stride =   2, RF size =  26\n",
      "Layer Name = pool2, Output size =  18, Stride =   4, RF size =  28\n",
      "************net structrue name is ACCNN1**************\n",
      "Layer Name = conv1, Output size =  88, Stride =   1, RF size =   9\n",
      "Layer Name = conv2, Output size =  80, Stride =   1, RF size =  17\n",
      "Layer Name = conv3, Output size =  76, Stride =   1, RF size =  21\n",
      "Layer Name = pool1, Output size =  38, Stride =   2, RF size =  22\n",
      "Layer Name = conv4, Output size =  34, Stride =   2, RF size =  30\n",
      "Layer Name = conv5, Output size =  30, Stride =   2, RF size =  38\n",
      "Layer Name = pool2, Output size =  15, Stride =   4, RF size =  40\n",
      "************net structrue name is ACCNN2**************\n",
      "Layer Name = conv1, Output size =  88, Stride =   1, RF size =   9\n",
      "Layer Name = conv2, Output size =  84, Stride =   1, RF size =  13\n",
      "Layer Name = conv3, Output size =  40, Stride =   2, RF size =  17\n",
      "Layer Name = pool1, Output size =  20, Stride =   4, RF size =  19\n",
      "Layer Name = conv4, Output size =  16, Stride =   4, RF size =  35\n",
      "Layer Name = conv5, Output size =  12, Stride =   4, RF size =  51\n",
      "Layer Name = pool2, Output size =   6, Stride =   8, RF size =  55\n",
      "************net structrue name is ACCNN3**************\n",
      "Layer Name = conv1, Output size =  88, Stride =   1, RF size =   9\n",
      "Layer Name = conv2, Output size =  42, Stride =   2, RF size =  13\n",
      "Layer Name = conv3, Output size =  38, Stride =   2, RF size =  21\n",
      "Layer Name = pool1, Output size =  19, Stride =   4, RF size =  23\n",
      "Layer Name = conv4, Output size =  19, Stride =   4, RF size =  39\n",
      "Layer Name = conv5, Output size =  19, Stride =   4, RF size =  55\n",
      "Layer Name = pool2, Output size =   9, Stride =   8, RF size =  59\n",
      "Layer Name = conv6, Output size =   9, Stride =   8, RF size =  75\n",
      "Layer Name = conv7, Output size =   9, Stride =   8, RF size =  91\n",
      "Layer Name = pool3, Output size =   4, Stride =  16, RF size =  99\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
