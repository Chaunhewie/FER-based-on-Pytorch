{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72379,
     "status": "ok",
     "timestamp": 1556208136676,
     "user": {
      "displayName": "Chaunhewie Tian",
      "photoUrl": "https://lh4.googleusercontent.com/-K_cnsi_ZdWw/AAAAAAAAAAI/AAAAAAAAAA8/VXOJ9SNCpuw/s64/photo.jpg",
      "userId": "07759722813896836245"
     },
     "user_tz": -480
    },
    "id": "8tTKUKdNF90j",
    "outputId": "03ce0c5f-4138-4f9d-8823-2c696b5b5c50"
   },
   "outputs": [],
   "source": [
    "# 获取授权\n",
    "!apt-get install -y -qq software-properties-common module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9247,
     "status": "ok",
     "timestamp": 1556208150144,
     "user": {
      "displayName": "Chaunhewie Tian",
      "photoUrl": "https://lh4.googleusercontent.com/-K_cnsi_ZdWw/AAAAAAAAAAI/AAAAAAAAAA8/VXOJ9SNCpuw/s64/photo.jpg",
      "userId": "07759722813896836245"
     },
     "user_tz": -480
    },
    "id": "eW8YCA7BGVMG",
    "outputId": "2526cb43-c930-4ced-d6b4-92fafab78ef8"
   },
   "outputs": [],
   "source": [
    "# 指定Google Drive云端硬盘的根目录，名为drive\n",
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rhgBEpBhIcap"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"drive/my_scripts\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10969,
     "status": "ok",
     "timestamp": 1556208155069,
     "user": {
      "displayName": "Chaunhewie Tian",
      "photoUrl": "https://lh4.googleusercontent.com/-K_cnsi_ZdWw/AAAAAAAAAAI/AAAAAAAAAA8/VXOJ9SNCpuw/s64/photo.jpg",
      "userId": "07759722813896836245"
     },
     "user_tz": -480
    },
    "id": "cEpeEkcdLDt-",
    "outputId": "e3beea04-3f28-452a-bfd4-ed0dee7c34dd"
   },
   "outputs": [],
   "source": [
    "# 云端默认没有face_recognition\n",
    "!pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20650,
     "status": "ok",
     "timestamp": 1556208168510,
     "user": {
      "displayName": "Chaunhewie Tian",
      "photoUrl": "https://lh4.googleusercontent.com/-K_cnsi_ZdWw/AAAAAAAAAAI/AAAAAAAAAA8/VXOJ9SNCpuw/s64/photo.jpg",
      "userId": "07759722813896836245"
     },
     "user_tz": -480
    },
    "id": "pJp72yYwKBAY",
    "outputId": "69753eb4-ad68-44fa-d5e5-7fbe734c05e0"
   },
   "outputs": [],
   "source": [
    "!ls\n",
    "!nvidia-smi\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1031,
     "status": "ok",
     "timestamp": 1556210324383,
     "user": {
      "displayName": "Chaunhewie Tian",
      "photoUrl": "https://lh4.googleusercontent.com/-K_cnsi_ZdWw/AAAAAAAAAAI/AAAAAAAAAA8/VXOJ9SNCpuw/s64/photo.jpg",
      "userId": "07759722813896836245"
     },
     "user_tz": -480
    },
    "id": "e_WoO8cMFPbl",
    "outputId": "5f5ec469-2862-42e2-89dc-8d27688b146b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available:  True\n",
      "using DEVICE:  cuda\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "# 用于重新加载模块\n",
    "import importlib\n",
    "\n",
    "import networks.ACNN as net_ACNN\n",
    "importlib.reload(net_ACNN)\n",
    "ACNN = net_ACNN.ACNN\n",
    "import networks.ACCNN as net_ACCNN\n",
    "importlib.reload(net_ACCNN)\n",
    "ACCNN = net_ACCNN.ACCNN\n",
    "from networks.AlexNet import AlexNet\n",
    "from networks.VGG import vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn\n",
    "from networks.ResNet import resnet18, resnet34, resnet50, resnet101, resnet152\n",
    "import dal.JAFFE_DataSet as JAFFE_DataSet\n",
    "import dal.CKPlus_DataSet as CKPlus_DataSet\n",
    "import dal.FER2013_DataSet as FER2013_DataSet\n",
    "# importlib.reload(JAFFE_DataSet)\n",
    "# importlib.reload(CKPlus_DataSet)\n",
    "# importlib.reload(FER2013_DataSet)\n",
    "JAFFE = JAFFE_DataSet.JAFFE\n",
    "CKPlus = CKPlus_DataSet.CKPlus\n",
    "FER2013 = FER2013_DataSet.FER2013\n",
    "import transforms.transforms as transforms\n",
    "import utils.utils as utils\n",
    "use_cuda = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if use_cuda else \"cpu\")  # 让torch判断是否使用GPU，建议使用GPU环境，因为会快很多\n",
    "print('cuda available: ', use_cuda)\n",
    "print('using DEVICE: ', DEVICE)\n",
    "enabled_nets = [\"ACNN\", \"ACCNN\", \"AlexNet\", \"VGG11\", \"VGG13\", \"VGG16\", \"VGG19\", \"ResNet18\", \"ResNet34\", \"ResNet50\",\n",
    "                \"ResNet101\", \"ResNet152\"]\n",
    "enabled_datasets = [\"JAFFE\", \"CK+\", \"FER2013\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0scksgMFPbw"
   },
   "outputs": [],
   "source": [
    "class OPT:\n",
    "    def __init__(self):\n",
    "        # Other Parameters\n",
    "        # 是否使用面部标记点进行训练\n",
    "        self.fl = True\n",
    "        # 存储的模型序号\n",
    "        self.save_number = 5\n",
    "        # 批次大小\n",
    "        self.bs = 32\n",
    "        # 学习率\n",
    "        self.lr = 0.01\n",
    "        # epoch\n",
    "        self.epoch = 200\n",
    "        # 每次获得到更优的准确率后，会进行一次存储，此选项选择是否从上次存储位置继续\n",
    "        self.resume = True\n",
    "        # 表示一开始的lrd_je个epoch，lr增大来解决一开始的收敛缓慢问题\n",
    "        self.lre_je = 20\n",
    "        # 表示默认从第 $lrd_se 次epoch开始进行lr的递减\n",
    "        self.lrd_se = 180\n",
    "        # 表示默认每经过2次epoch进行一次递减\n",
    "        self.lrd_s = 2\n",
    "        # 表示每次的lr的递减率，默认每递减一次乘一次0.9\n",
    "        self.lrd_r = 0.9\n",
    "        \n",
    "#         self.model, self.epoch, self.bs = 'ACNN', 1000, 128\n",
    "        self.model, self.epoch, self.bs = 'ACCNN', 2000, 64\n",
    "#         self.model, self.epoch, self.bs = 'AlexNet', 500, 32\n",
    "#         self.model, self.epoch, self.bs = 'VGG11', 200, 32\n",
    "#         self.model, self.epoch, self.bs = 'VGG13', 200, 32\n",
    "#         self.model, self.epoch, self.bs = 'VGG16', 200, 32\n",
    "#         self.model, self.epoch, self.bs = 'VGG19', 200, 32\n",
    "#         self.model, self.epoch, self.bs = 'ResNet18', 200, 32\n",
    "#         self.model, self.epoch, self.bs = 'ResNet34', 200, 32\n",
    "#         self.model, self.epoch, self.bs = 'ResNet50', 200, 32\n",
    "#         self.model, self.epoch, self.bs = 'ResNet101', 200, 32\n",
    "#         self.model, self.epoch, self.bs = 'ResNet152', 200, 32\n",
    "        self.lre_je = int(self.epoch*0.1)\n",
    "        self.lrd_se = 1750\n",
    "        self.lrd_s = 20\n",
    "        \n",
    "#         self.dataset = 'FER2013'\n",
    "#         self.dataset = 'JAFFE'\n",
    "        self.dataset = 'CK+'\n",
    "opt = OPT()\n",
    "\n",
    "\n",
    "train_acc_map = {'best_acc': 0, 'best_acc_epoch': -1, 0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}\n",
    "test_acc_map = {'best_acc': 0, 'best_acc_epoch': -1, 0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0}\n",
    "Train_acc, Test_acc = 0., 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56468,
     "status": "ok",
     "timestamp": 1556210388903,
     "user": {
      "displayName": "Chaunhewie Tian",
      "photoUrl": "https://lh4.googleusercontent.com/-K_cnsi_ZdWw/AAAAAAAAAAI/AAAAAAAAAA8/VXOJ9SNCpuw/s64/photo.jpg",
      "userId": "07759722813896836245"
     },
     "user_tz": -480
    },
    "id": "kJSsPjSmPbz9",
    "outputId": "279e7da1-72d9-4f12-b994-acc1b48683b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Preparing Data...----------------\n",
      "train_num:  906  test_num: 75\n",
      "train_num:  906  test_num: 75\n",
      "------------CK+ Data Already be Prepared------------\n"
     ]
    }
   ],
   "source": [
    "reset_dataset = False\n",
    "if reset_dataset:\n",
    "    criterion, target_type = nn.CrossEntropyLoss(), 'ls'\n",
    "    print(\"------------Preparing Data...----------------\")\n",
    "    if opt.dataset == \"JAFFE\":\n",
    "        train_data = JAFFE(is_train=True, transform=None, target_type=target_type, using_fl=opt.fl)\n",
    "        test_data = JAFFE(is_train=False, transform=None, target_type=target_type, using_fl=opt.fl)\n",
    "    elif opt.dataset == \"CK+\":\n",
    "        train_data = CKPlus(is_train=True, transform=None, target_type=target_type, using_fl=opt.fl)\n",
    "        test_data = CKPlus(is_train=False, transform=None, target_type=target_type, using_fl=opt.fl)\n",
    "    elif opt.dataset == \"FER2013\":\n",
    "        train_data = FER2013(is_train=True, private_test=True, transform=None, target_type=target_type,\n",
    "                             using_fl=opt.fl)\n",
    "        test_data = FER2013(is_train=False, private_test=True, transform=None, target_type=target_type,\n",
    "                            using_fl=opt.fl)\n",
    "    else:\n",
    "        assert(\"opt.dataset should be in %s, but got %s\" % (enabled_datasets, opt.dataset))\n",
    "    print(\"------------%s Data Already be Prepared------------\" % opt.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 7\n",
    "net_to_save_dir = \"Saved_Models\"\n",
    "net_to_save_path = os.path.join(net_to_save_dir, str(opt.save_number), opt.dataset+'_'+opt.model+'_'+str(opt.save_number))\n",
    "if opt.fl:\n",
    "    saved_model_name = \"Best_model_fl.t7\"\n",
    "    saved_temp_model_name = \"Best_model_fl_temp.t7\"\n",
    "    model_over_flag_name = \"__%d_success_fl__\" % (opt.epoch)\n",
    "    history_file_name = \"history_fl.txt\"\n",
    "else:\n",
    "    saved_model_name = \"Best_model.t7\"\n",
    "    saved_temp_model_name = \"Best_model_temp.t7\"\n",
    "    model_over_flag_name = \"__%d_success__\" % (opt.epoch)\n",
    "    history_file_name = \"history.txt\"\n",
    "over_flag = False  # 如果已经成功训练完，就可以结束了\n",
    "TEMP_EPOCH = 2  # 用于暂时存储，每TEMP_EPOCH次存一次\n",
    "temp_internal = TEMP_EPOCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54545,
     "status": "ok",
     "timestamp": 1556210388905,
     "user": {
      "displayName": "Chaunhewie Tian",
      "photoUrl": "https://lh4.googleusercontent.com/-K_cnsi_ZdWw/AAAAAAAAAAI/AAAAAAAAAA8/VXOJ9SNCpuw/s64/photo.jpg",
      "userId": "07759722813896836245"
     },
     "user_tz": -480
    },
    "id": "fRl8SEjlFPby",
    "outputId": "1b99ad62-751b-4c91-b4aa-ca348f56c5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Preparing Model...----------------\n",
      "Initializing ACCNN weights...\n",
      "Init ACCNN model over!\n",
      "==> Loading Model Parameters...\n",
      "------------ACCNN Model Already be Prepared------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------Preparing Model...----------------\")\n",
    "if opt.model.lower() == \"ACNN\".lower():\n",
    "    net = ACNN(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"ACCNN\".lower():\n",
    "    net = ACCNN(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"AlexNet\".lower():\n",
    "    net = AlexNet(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"VGG11\".lower():\n",
    "    net = vgg11_bn(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"VGG13\".lower():\n",
    "    net = vgg13_bn(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"VGG16\".lower():\n",
    "    net = vgg16_bn(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"VGG19\".lower():\n",
    "    net = vgg19_bn(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"ResNet18\".lower():\n",
    "    net = resnet18(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"ResNet34\".lower():\n",
    "    net = resnet34(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"ResNet50\".lower():\n",
    "    net = resnet50(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"ResNet101\".lower():\n",
    "    net = resnet101(n_classes=n_classes).to(DEVICE)\n",
    "elif opt.model.lower() == \"ResNet152\".lower():\n",
    "    net = resnet152(n_classes=n_classes).to(DEVICE)\n",
    "else:\n",
    "    net = None\n",
    "    assert(\"opt.model should be in %s, but got %s\" % (enabled_nets, opt.model))\n",
    "start_epoch = 0\n",
    "if opt.resume:\n",
    "    # Load checkpoint.\n",
    "    print('==> Loading Model Parameters...')\n",
    "    if os.path.exists(os.path.join(net_to_save_path, saved_temp_model_name)):\n",
    "        if os.path.exists(os.path.join(net_to_save_path, model_over_flag_name)):\n",
    "            print(\"Model trained over flag checked!\")\n",
    "            over_flag = True\n",
    "        assert os.path.isdir(net_to_save_path), 'Error: no checkpoint directory found!'\n",
    "        checkpoint = torch.load(os.path.join(net_to_save_path, saved_temp_model_name))\n",
    "        net.load_state_dict(checkpoint['net'])\n",
    "        test_acc_map['best_acc'] = checkpoint['best_test_acc']\n",
    "        test_acc_map['best_acc_epoch'] = checkpoint['best_test_acc_epoch']\n",
    "        start_epoch = checkpoint['cur_epoch'] + 1\n",
    "    else:\n",
    "        print(\"Checkout File not Found, No initialization.\")\n",
    "print(\"------------%s Model Already be Prepared------------\" % opt.model)\n",
    "\n",
    "# for gray images\n",
    "IMG_MEAN = [0.449]\n",
    "IMG_STD = [0.226]\n",
    "\n",
    "crop_img_size = int(net.input_size*1.2)\n",
    "input_img_size = net.input_size\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(input_img_size),  # 缩放将图片的最小边缩放为 input_img_size，因此如果输入是非正方形的，那么输出也不是正方形的\n",
    "#     transforms.Resize(crop_img_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "#     transforms.Resize(test_img_size),\n",
    "#     transforms.TenCrop(input_img_size),\n",
    "#     transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMG_MEAN, IMG_STD),\n",
    "])\n",
    "\n",
    "test_img_size = int(input_img_size * 1.1)  # 测试时，图片resize大小\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(input_img_size),  # 缩放将图片的最小边缩放为 input_img_size，因此如果输入是非正方形的，那么输出也不是正方形的\n",
    "#     transforms.Resize(crop_img_size),\n",
    "#     transforms.TenCrop(input_img_size),\n",
    "#     transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMG_MEAN, IMG_STD),\n",
    "])\n",
    "\n",
    "# 随机梯度下降\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=opt.lr, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "train_data.set_transform(transform_train)\n",
    "test_data.set_transform(transform_test)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=opt.bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=opt.bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), dilation=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (10): ReLU(inplace)\n",
      "    (11): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (12): ReLU(inplace)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.6)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Linear(in_features=1600, out_features=512, bias=True)\n",
      "    (3): Dropout(p=0.6)\n",
      "    (4): Linear(in_features=512, out_features=7, bias=True)\n",
      "    (5): Softmax()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VbnQAQuBP0BD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df38417630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df69765cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAL0AAAC7CAYAAAAwjp8tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXt03HWZ/1+fuWRyb9q0SQq9RgqlW0RESrdwEBC5CCq7FEWQyy4ssguCsr8jCruKbs+uCOqyu6LgYpGLUhUtgmcF5bpdd0sLCMUWQttAG+glbUlzz8xkPr8/vnmefL6TaTNJZiZJ5/s+J2cm3+vn+53n83ye+2OstQQIUEwIjfcAAgQoNAKiD1B0CIg+QNEhIPoARYeA6AMUHQKiD1B0GBPRG2PONsa8YYzZbIz5cq4GFSBAPmFGa6c3xoSBJuCjQAuwDviMtXZj7oYXIEDuMRZOvwTYbK3daq2NAw8Dn8zNsAIEyB/GQvSHA9ud/1sGtgUIMKERGcO5JsO2IbKSMeZq4OqBf48fw/0CBBgW1tpMdOnDWIi+BZjt/D8LeDfDIO4B7gEwxgSBPgHGHWMRb9YBC4wx840xJcBFwK9zM6wAAfKHUXN6a23SGHMd8AQQBn5krf1TzkYWIECeMGqT5ahuFog3AfKMbGT6wCMboOgQEH2AokNA9AGKDgHRByg6BEQfoOgwFudU0SEcDrN48WIAampqdPtzzz03XkMKMAoEnD5A0SGw0zsIhULEYjEAenp6huyvqKjgkUceAeCkk07S7eedd96QY+W9GuM3GwerQn6R79ibQwaHH+4Fh65YsYKZM2cCcMEFFww5rqKigoqKCv0uePzxx7O+V6YJsmvXLgBef/317AcdYNQIxJsARYdAvAGOOOIIAB599FHmzJkDwLp16wBP5AmHwwAsXryY6upq37mpVIpQyOMd1loyvU/ZHwqF6OzsHLL/4YcfBuDqq6/OeH6A7BGEIQQIkAGBTO+gv79fOe0pp5wCDHJpgEQiQVdXFzCo6HZ0dKhOkEwmM143Go0CEIlEqKys9O174IEHuPpqL8cm4PKFQUD0Dvr7+4nH4wCUlZUBnvjS398PwP79+1Xp3L17NwBbt25l6dKleqwQbiKRADxCFvEoEolwzDHH+O45Z84cli9fPmQsP//5z3P6bJkwbdo0YPBZXbzzzjt5v/94IRBvAhQdio7Tu0oleHb0kpISwOP03d3dAGqvT6VS7N27F4BNmzbx9ttvA+i2/fv3s2/fPj1fRJxUKgVASUmJijdnnnkmzc3NwKBHd+nSpT6bvwtZLZ5//nkAvU8uEA6H+drXvgbAOeeco9tlpTr99NN124IFCwA49thj9bmstboCfv/738/ZuAqBoiN6+QE/8IEPAJ54IaEFJSUlal0Rp1JraysbNmwA4O2332bq1KkAvO997wM8Ql+7di3gt/SUlpYCHnEJ0T/77LM6mWprawFYuHChXisWi+lk/MlPfqJjOeusswB44YUXsn7OI444guOOO27IdhGbjDHqk5D7u+LZ008/rd/FYjVt2jQl+v7+fp8IJ5/79+8HPN9FJkvVREAg3gQoOhQdpxcOfNhhhwFw4okn8md/9meAn1O99957ADQ1NalYMWfOHOWKv/zlLwH4wx/+wGc/+1k9R6w7svT39vbq92g0qpxcxKCmpiYVr2bNmqVKZSQS0VUjPZQhG5x77rnccccdvm0uJw+FQjQ0NPjGkkwmlXvPmTNHt4ty397e7rMwCdf/+te/rs/81ltvAbBmzZoJy+mLiugXLVrEmWeeCQyKDPPmzdMfdefOnUq0ra2tgEeIJ554IuAt7zfccIPvmmvXrlXi6OvrU6IRQneJ5PLLL9f9rsVECKW6ulon5WgI3YUraglxAtx///2AR8gyNpnoHR0dap2aPXs27e3tuh28CSwTtLy8XL9XVVXp9WXcpaWllJeX63a5V6aYpkIjEG8CFB2KitPDoFImCmlJSYlywilTpuh+cSI1NTWxefNmwONiwpVFeQV48cUXs7r3mjVr+Mu//EsAn8I7a9YswLPOyH0rKirG7KyS5xKLFOBzrsl3EeV27NjB9u1epcbGxkbdLuf39vaqeFZZWanvUIwC4XBYt91xxx309fUBfrHpb//2bwGP88v+QjvlAk4foOgwLKc3xswG7gcagBRwj7X2TmPMNGAVMA94C/iUtfa9/A117CgtLaWxsRGAuro6ILOZEVAlbMWKFbS0tOj2sXClXbt2EYl4r1zuGQqFVHZubGxUTtre3q56h7uqDIcvfvGLANx22220tbX59vX09Oi9du/erb4G8S63tbWpzL1u3TqfeRI8nUX0l97eXuXeM2bMALxVVMyzRx11lD6rHA/w7//+74C3qnz3u98Fcut/yAbZiDdJ4O+ttS8ZY6qAF40xvwOuAJ6y1n5zoCHDl4Gb8jfUsWPKlCkcddRRwKD44ip0qVRqyA/tWjwAVc7kBxUiygaucuou7UJ0yWRSnVZiQx8pZKx9fX2qoMu93nvvPbZs2QJ4SrtMCiFIV+F1RSLXDi+EHg6H9TzJJzjyyCPVKlZdXa0Krpt78MEPfhDwwjdEES40hhVvrLU7rLUvDXzvADbhleT+JPDjgcN+DJyfr0EGCJBLjEiRNcbMA44D1gL11tod4E0MY0xdzkeXY9TV1TFv3jwAH5cRUcPl6MLF3G3GGE477TRg0Iu5cuXKjCKPcHVjjH5vampixYoVvuPcKM5QKKQryKpVq5RDjwQifvT09Ci3Fg4eiURUhCstLdVxi6fXNSeefPLJQ8ym8XhcTa3WWlVaRTzZunWrKsezZ89W77MbsiBhGDfccAM7d+4c8fPlAlkTvTGmEngE+IK1tj1bO3JaffpxxZ49e3jyySeBQWLu7+/XH6qzs1OJOt3FLhCiFDn2s5/9rBJuNBrNaF+X/ffee+8QObu7u1vFEBef/vSnNc5nJHD9DGJfl+vX1NQo0VdUVChRvvzyy4D3fgThcFjHLdfcsmVLxgn+N3/zN4An6kl0ZnNzs4Z3zJ07V0Wd8bLYuMjKemOMieIR/EPW2l8ObN5ljJk5sH8msDvTudbae6y1H7LWfigXAw4QYKzIxnpjgHuBTdba7zi7fg1cDnxz4PPRvIzwABCRRJbNbPDcc89lrEbgcp1/+qd/AvwWBdeqI4qspBXOnDmT+vp6wFPe0mPTOzs7VVGNRqNq3ZDxr169mj/+8Y9DxuQmics5mcSNdPz6116LgLVr16pYI5933nmnel97enp8Cmo6sqnaIPH427ZtA+Dss89W8aWlpUVXkLa2No4//ni9rzum8UA24s1JwKXABmOM/Do34xH7z4wxVwLbgAvzM8QAAXKLYYneWruGzP2lAD6S2+FkD+Ey3d3dQ5RNGFRUS0tLddu77w7pDjQEEptyySWXAHDVVVepzb6+vl7l3Ndeew2A0047TeV/d3WQ+8diMfUJNDQ0qJwt+11bdjrE1CcBXQsWLPBx+0wZV6IziA3exXXXXedbGUXpFe4/UqTb1xsbG30ebeH6mzdvVgOCjH/RokUa39TV1aXe35GYgEeLSVsNQQjpwx/+sG8ZF/FDXOOnnHIKf/EXfwF4P5JYZQ4EOe+mmzyXQ19fnxLSrl271OIg9+/u7lblzBij9xeRqLy8XG3vU6ZM0YCuVatWAbBhwwafpUeW/5qaGlW6BSeccILv/8cee8z3fzKZ1GJUDz300EGfM5eQJJizzjpLxx+PxzV3uKOjQ9+H5BH09/frxHzzzTe1+oQwk9EiqIYQIEAGTNqAM1maxewGnqgwffp0APW8Hn300TzxxBMAXH/99TzzzDMjun48HtdlePv27Rx55JEAqpi9+eabyr0bGhqUq8v5LS0tqtyWlJQwe7bXkFFCDE4++WT1DldWVvIP//APgMf1RdkVL2Y6Pv7xjwOD5tXbbrvtoBzeGKMKOHgrDwwqlclkUr83NTUd5O348T//8z+Al1sgKC8vV7Fs7ty5GqgnK0Fpaaly/1gsVlAT5qQlepFN29vblTimTJmiy6fY0UtKSpRQ08tvHAyu00gm1qxZs9TNLtffu3ev2tO3bt2qoorsP+yww5g/fz7gLd0iy0vaIgzG1k+bNo1ly5YBfrFnJGM9GIwxOlGOP/74IQ64adOmad7swoUL9Ty3tIlbo1OiT9P3yXd5b1OnTlVbv/xW4XBYdZbq6uox5w+MBIF4E6DoMGk5vaC7u9vnZZQlWz7D4fCIbPliTRErRElJiW6LRqO6XbaVlZWpSONmHgn3dgPHlixZopUNhHsec8wxuiqEQiE9XpLRs4Frbxeuv3jxYl31ZP/zzz+v78IYo+mCIhLW1NTwne94rhj3vYlFZdeuXWplSSaT/PCHPwQGozRh0I/xz//8z2qx6e3t1ffmhnyIgWDNmjVjVmBHgoDTByg6TEpOX1dXpwpRf3+/zxzmcngYuedP5FDhuKlUShXZ7u5u5aTiDa2vr1czZkNDg56XSUmbM2cOixYtAgZzcHt7e9WjW1FR4csrHQ1kBVq+fLmaOGVVSSQS6t+ora3VeBjhuK+//rqvBo9wepHHKysrleu3traqMv9f//Vfeo48azwe13dvjBniiQ6Hw7rCyYpUKExKog+Hw5x/vhfJXFpaqorqEUccoWXzXKL91Kc+BQy1a6dj0aJFSqySwhePx5WQtm3bpgQuaXWnnnqqWlfeffdd/QFFSaurq1OF0bWezJ07F/AUXplosVhsRMp2OtyIzqlTp+o9JIb+85//vE/pFWedBJr19fXxwAMPAN5kTA9jSCaT+l4bGhoyWlxkW1dXl04Qa62PCYAnNsp3Ea8KhUC8CVB0mJSc3jVTxmIxX1VgdymHwWCtbLBx40auueYaYLBmfDKZZMmSJYCnHMuSLwrdunXr9B6hUEg5qXhp29ra1DwZjUbVTi/nlJeX+zyybljCSE2W8k7AU0rlXiIKvvvuu8rVOzo6NCdAztu5c6fev6qqio0bN+p3uc/69esBbyURDi3cPxQK6aqwcuVKX87CV7/6VWBQ/DLG6Kowkt8oF5iURN/V1aUvv6KiQh0pNTU1mtiQntaXLa6//nrf/zU1NVrYacGCBUpAkrcaj8d1okUiEb2v6BYNDQ0auzNlyhQVXzLZ1m+88Ubuu+8+wCurJyERw0EmRyQS0e+xWGyI63/Lli06vsrKSrWu7NixA/CsMBJe0dbWpkQt7/CYY47RSfPf//3fWjZQGEU0GlX94K677vIVe/rGN77hu5aL9ByDfCMQbwIUHSYlp4eRBSZJe53RIJlMamy7m74nlov+/n4VD0pKSpSDi5JWUVGhlp5YLMazzz4LMMSbCSOzzcOg0ii29a9+9as8+OCDgFfWT8YiSvexxx6r46qqqmLNmjW+sXR3d+t7bWlp0ZVAlPJIJML73/9+wLPZSx6AZEjV19fr9dNFs0zPO14IOH2AosOk5fTCUerr61VhSiQSPpMYeLLzq6++Our7dHV1aS0ZVw6XEN50vPLKK8BgEJYxRpViay0/+tGPgAOH/opOMlpkavomukFvb69uKykpUZ+BmFTb2tr4/e9/D3jmW/Eqi5m1rq5OV4J4PK7yv+gOra2t3HXXXcBg/cuJiElL9GKDvuWWWzSgq6mpSb/L0lxWVsbZZ58NeMnKI/0x3PJzLjL1mQWGWI8ALrroIv0uKXT5gOvab21tVQYgDqlUKqV+BjfpXKxL1lq1rbu5CULcPT09SuDTp0/32eHBe/ZsoyXd8I1UKqUioFjF8olAvAlQdJiUnH7JkiV873vfAzzPqShkomTBYHubkpISfvOb3wBw2WWXZR1PPxxGUnJ6OE/waJFejS0ej6s9/Fvf+paKOk8//TTgiYTCvffu3avlCiXtr6enR73L+/fv1+tLOuHevXt1pYxEIhpGIO+6ra0t6zDnpUuXqnm4o6ODN954A4Bvf/vb+kxuIJ3b9mesmJREH4lEdMl1Y72TyaSGJLh9pP76r/8aIGcEP1EgIpSIBtZaX91NwRlnnAF4E+HDH/4w4L0fmQAi6rz33ntqkUkkEkMILBQKabTk/v371Wkl9nzXejUcKioq1KlVU1OjIqRMuj179mixqng8rqmFI4mYPRAC8SZA0WFScnq3I2BHR4ev+0chM3DGG26VtoNB/AzNzc26Err+BckGa2xs5H//93/1vPRqzrFYTD2qe/fuVe+yeHxLS0t9oRDDjd0VWVxrHHhWs/QCtLlCwOkDFB1GUssyDKwH3rHWnmeMmQ88DEwDXgIutdYOLbmVJwgXcMt69Pf3+0psTzZMnTpVlc7h4m6SyaTWd7/11lsPeqy8k1tvvZXbb78dGFqYFuDwww/nzjvvBDylVvQlt/eucORXXnlFx+r6SbJtrmaM8TWdkxVEzKviRZb9uUwcH4l4cwNeme7qgf9vA75rrX3YGPMD4EqgYF105Qfp7OxUS0oikRhi0YDxLRY6EoTD4azFg3A4nHV9d3n+1tZWTV7JhPnz53PjjTcCfuuJCyHUE088MavSfweD2+xBRFRRlKuqqtRSVFlZqZMpF8ws2wKus4Bzgf8c+N8ApwO/GDgkqE8fYNIgW07/r8CXAOmdWAu0WWvFXtiC16ihIHjjjTc0BjsWi+ns7+zsHFLBrNCx2mNBfX29KnLDwa2LkyuMxKQrvpGR4pxzzgHgS1/6knL6RCLhMz2DZ9IUU2g4HFZPrevpHi2yqVp8HrDbWvuiMeZU2Zzh0IwyRL7q01933XWAt9y5ruv0agV33313Tmy7hYBb1Xg4TBaRLR0y7kQiobb31tZWjcKU2H63BujTTz+d00bM2VYt/oQx5mNAKZ5M/69AjTEmMsDtZwEZq6Naa+8B7oHc1rIMEGC0yKZq8VeArwAMcPr/Z629xBjzc2A5ngWnoPXp9+zZo3XYh8NIOvNNNuTafl0IiM/gP/7jP9QC19XVpVlYYklKJpM5FWlcjMVOfxNwozFmM56Mf29uhhQgQH4xIo+stfZZ4NmB71uBJbkfUnYQec8tbppJdv/d735XsDEdCPnwEqdSKf70pz/l/Lr5hhRylU9BenvPZDLpK/udS0zKMAQYTNe7//77fUWJRFESe/LnPvc5tQy89NJLo25AMFpceumlWk3BbeomS3dXV5dGK15zzTW+H12QKdowEokMW2t/IkFKCGaKoU8kEhlbEOULQRhCgKLDpOX0rmvcDT1Ib0N/9913q7nrsssuKyhHAS+cQGzTO3bs0GKnUnVs+/btqqht375dxbYdO3Yot5fPvr4+jX3/9re/nbUyPxHwyU9+EoDzzjsP8FY68Q7v2bNH0yjdamoi8uTaPDtpiT69oq4g/QWFw+ER177JNeSHbGtr0z6rUt24tbVVa8m88sor6mdwJ7PbIEIqO8yYMUPFJmEAZWVlvlqYkjwzEeAyKfB+F7eRs0wKEXncnr+5lukD8SZA0WHScnqxiHR2dqoloLGxUcUa12Iynh5ZN/a/trZWFVgRc2bMmKFjbW5uVqU2mUyq2OPGnYuoNmPGDI3ElHj2WbNmaRhDVVUVL730EjDo5RwvXHPNNSriiRe2ra1N30F7e7uviC14NXjylRsxaYleXtgzzzyjhF5bWzvk5cXj8XFtzR6NRn0VjNNbz7vxM/F4XLe7VRhcopdJs23bNk2nk0ldVlamE6y8vFz7bo030adSqYwh32J96u3t1ckuYt+jjz6aN+dbIN4EKDpMSk6/ePFirrjiCsArVScWj66uLi2cKlywo6ODq6/24t3GUvRptAiHw6pcut9l6d62bZtyvHfeecdX1VeCz0SRSyaT6mcIhUKamJ1+HPibRo83+vv7lWu7zyKrWiKR0BXPrZCcLwScPkDRYVJy+kQioVk1+/btY+vWrYDH6ZcuXQrg66IxnqmDoVDIV79edA3ZNm3aNP7v//4PQDtsg/eMrscSvGcRRdYt/+fqMZJuN2XKlLxyy5Ggv79fn0E+k8mkmmKj0WhBV6VJSfTbtm3TmonhcNin6MmPfu+9XvxbZ2fnuBC9EOLChQu1wsCiRYt0fCLGlJeXa3OEnp4ency9vb1aS9JVwCUexS025eaXikJYUVGR8yST0cLNnRWxs7u7W0We2tpaX+VnyE+8kmBisIIAAQoIU0gzXr6SSNz2NQKpmZ5MJmlubgZGVoovV6ioqFDu9eCDD/Kxj30M8AeRiTu+ra1N7dg9PT2+Y8ATE6SCmRtyIcrfggULdCW59tprefzxx/P+fNlg1qxZOi43RVB+j/Lycq688kpgsMTgv/3bv+mqMBJYa4ddIialeOMiFotx6qmnAt7yLmKFdMlzEQ6HlYAKJfJ0dXX5ilEJ3AkqkYduee14PD5kiU+lUioHp1IpldnlWTo6OnT/eERgGmO0mBSg9SlbWloylht0Ic0kROTJZ4JMIN4EKDpMek4fCoW0vvqyZcu0N+q//Mu/AB73dAO3/vCHPwDw29/+NudjOfbYY7WPrXCu4eDa48vKytRiU15ertuF47srgRuPLk3MNm3apNc9WH2bfCEcDqv4duSRR/KDH/wA8NfQEZEsEomoz2HLli0F9aEEnD5A0WHScnox58Fgq5cNGzaoUrds2TLA80y6nTIktiMf+PjHP87NN98M+LmzcOzDDz9c5W+RWfv7+zU2p6ysTOV0dwUQuGULrbW6qgmHT0/BGw+48fAXX3wx4Oknsl2etbKyUpPEpZRgoTBpiV4I+YILLtBUtPLycnXwuPXp5YU//PDD2swhH+jv71dFcuXKlYAnfrmTTgh127ZtgDdhpWZ8JBLRyew2F5bxG2M03t5aq0F3E6kqgohcPT09PmNBJgubm/CTXuwpnwjEmwBFh0nL6YVjlJWVqRiQSqU0k0o4h8sx8+Xlu+mmmwD4whe+oLZlWWni8bgvtFeWdOH0vb29euyUKVM0YA4Gk8fFm9nX18dJJ52k+8XUKVlHe/bsUfHnV7/6VS4fMWu4oRNuKIiIbbK/pKRk3Kq0TVqid1+YG2OSHmMeiUTy/nLlh+zs7PT1fwLPRr1x40bASxIR55MQdHd3t896I+54tymBW+xI0gVramqU6FesWAF4IoX7/CL+rFu3TrflE24OQCKR8JXiTo8Dmjdvnr6XQiPbqsU1xphfGGNeN8ZsMsb8uTFmmjHmd8aYNwc+x9YANUCAAiFbTn8n8Ftr7XJjTAlQDtwMPGWt/aYx5svAl/GqnhUU6QqfcEfheDU1NT6LRz7g9kBNb2SwadMmFWn27NmjSeASGrFv3z4VbyKRSMY2825kpjRlPvroo7Wqr9yrt7dXXftnnXWWr9Z8oeC+Y1mhenp6fG17wCvKKiEHhRZzhuX0xphq4BQGyvZZa+PW2jbgk3h16SGoTx9gEiEbTt8ItAIrjTHHAi/idSWpt9buALDW7jDG1OVvmEMhSlJLS4uvjLNwFJF96+rqlNPlS5EVTt/R0aE+Axlfc3Ozytatra0a+y8e00QioUVmw+Gwyvcu15dgrUWLFrFhwwbAyxGWNvduTXs3Xr1QED3k/PPPV5NxX1+fL/5HfgPJA2htbR1VQFkukA3RR4APAp+31q41xtyJJ8pkhXzVpxdCe/LJJzMSsxBCe3u7LvluH6OxQu4ZCoV0LOlRkuAt57Jt+/btWsBIzo9EIr7aPe51hZhE6a2vr9eOfr29vUMCztyaN7mu9HswyP2feuopbdZw4YUXKqFXVVWpCCMizdtvv611bQpdrSIbRbYFaLHWSs3rX+BNgl3GmJkAA5+7M51srb3HWvsha+2HcjHgAAHGimzq0+80xmw3xhxlrX0D+AiwceDvcuCbFLg+vQuXS8yYMUOrGItr2zWV5ZKjiL38vPPOUy9pZ2encu1MMfIdHR2qtEp1L9kucCuApWc+vfXWW8yaNQvwuLoow3LNhoYGPaevry+vCmI0Gh2S2eUWqF21apWuAG6SuqyAyWRy3NI4s7XefB54aMBysxX4K7xV4mfGmCuBbcCF+Rli9pgyZYoSvcR1V1ZWqmzpVv0Ve/Ldd989qnvNnj0bgFNPPVWjBXfv3q0/uvy43d3dqnNEo1HVOVzZWyYN+F3zQiiumCP7Z86cqdsltCEWiykh5js04X3vex9nnnkmgC/MQhjLT37yEz3WtSpNhFanWRG9tfaPQCbx5CO5HU6AAPnHpPXIDgcpI3fkkUeq+OAGhIlCuXr16hFFXl500UUA/N3f/R3gcV/h5Lt371au61pZRPyorq7WhmJyzvz5833Ka6bALOGk0WhUOaaMHwaVw/Lycg1jyLciG4vF1BLjRlbK90suucRXbVmKybpN8cYLQcBZgKLDIcfphdOIDdg1/bn7hZNOnTp1VDH2biaQKKUNDQ3KYaU1TigU0v1VVVVDzIyijApcDi82e0lyLykpUZk+FArptdwKZ8L1u7q6hqwauVRsXf3ILSUuMv3MmTN1he3s7Jww1dbgECR6+WHFiuJWDXAx2pr16cplLBbz2dzdCsXgiR5C9JWVlUMsMgdT7ORYl9BlmyvKSOBZbW2tft+/f79OlhdffHFUz3owuETsRlPKBHznnXeUAVRWVqqjbSIgEG8CFB0OWU6fqXuFu7wLxxxt6Tvh6G46YDKZVAVVktV37dqVcVXIBm7OQDp6enqGdN9zE7CXLl3Km2++OeLnGg7vf//7AS810r0veGKWcP3e3l7d/9hjj6mvYiLgkCN6IRS3Oq7ATWZIrzSQLdJFDvd7NBrVUABxIs2dO1ctLaWlpUrA8nmwAlQyNrlmKpVSn0N/f7/PkSXjyHerISFqNw3T1R3k+/Tp05UBjFeyyIEQiDcBig6HBKefM2cO4FVAkCTxM844A/Bzx0wYKaeX1L8XXngBgKOOOkqDwAD1rs6bNw/wOKJU+jLG8IlPfAIY9Jg+9NBDB7yXrAZyfdc6UlVVpV7hmTNn+o4vBFKpVEYO7ir6mVohTQQEnD5A0eGQ4PRSJ/FnP/uZmuzEIxqJRNRmH41GletLXql4SLNBOBzWfNMLLrgA8LirG8jmJnmDF6MiHLG1tVW5thx38cUX+0qNu95ZkdmlVkxra6uaAevq6jjssMOAQfNoel2cscjSoVBI36Vw7NbWVvVpPPch7LzZAAAMyUlEQVTccwdNuD/llFMmHIcXHBJE71oMfvjDHwJw3333AR7BSGKDG8QlhDQSuG1kMv3g0WhU94ttvru7WydAWVmZfhfi7Orq8kUjunZ8OUacPFVVVTruxsZGTReUbfF4PGeVmSsqKli+fDkwOIFXrlypz7158+YhVZVdixIMhkKMV7LIgRCINwGKDocEp3eR3qlj3rx5WmovGo0qBxbx4tprr9VzU6mU1qNxUxAzwfWkyvdEIqGmUBFjamtr9Z779+9XE6rruZWxVldX67HGGA1eE/NndXW1mi9jsZiGHIjI0dXVpV1N7rvvvjF1DDfG+ErwAVx66aW+ZxazsHD6devWqfdXWgpNRBxyRJ+OUCjkK5WX7vC5++67ffE6t9xyCwDr168/6HXd5gKuG95t/gseUc+dOxfwUuSEUOScmpoanQA1NTU+p5p0TRQ9ZP78+XpsMpnUySIT5fnnn9fJKlUXRgoRZa666iqV6WWsbtpfPB4f4hPIt48gVwjEmwBFh8kxNccI4e6JREIVTbGnu5WCI5HIsM3J3Cwh8DieKGx9fX0qCriZSyKSNDQ06FiEOzc1NWUM3nKjMyUGvbq62ldBLd2rHIvF+Na3vgWMPTUyUzx/KBTyWYdkrFLzX6o6THQEnD5A0aGoOH0kEvEVQxUId3ft5COBW2FN8mUF7e3tuqrU1dWpTC5ceuHChco93dDc9O7g4HFv0RXcUthuHftMgXajgTHG917k/gLXIzvRYmuGwyFL9JIgfvvttytxtLe3a+K2S2iu9WW4xGWZFCLeJBIJn8ghRCeTKpVKqZ3dnQAi8tTX1+u1ksmkT1EU64xMlLa2Nh1/KpUa4ubPdf2YdGJ2I1LdfRMh2XskCMSbAEWHQ5bTC9LT6oQrCRetqanRbTfffLMGkh3oWmIz/+lPfwp4pS7k/OOOO44lS5b4zuno6FAOXF5errbv448/HvBs7MLpXY9mIpHQMco57e3teq1YLOarnTNSuIVvXbii2sEK36ZSKV/IxGRCVkRvjPkicBVggQ14dW9mAg8D04CXgEuttbkRKHMAN55FxIBwOKw/kKQTuil4wy3TqVSKLVu2HHB/fX29XkPs5O3t7SryRKNRteMLIYdCIbXDJ5NJ/d7W1qbf02NgwCNaN40wm/G7mD17dsberiKWPfHEE3p9afrghnG41ptDTrwxxhwOXA98yFq7GAgDFwG3Ad+11i4A3gOuzOdAAwTIFbIVbyJAmTEmgVebfgdwOnDxwP4fA7cC38/1AEcLqTLwj//4jz7lU2zqV1xxhR7rutsliEtgrc061c0Yk5HrCafv6upSkcEVTdzuIW69GlFgZVWqrKzUiMrKykp9rkceeQTwokyHgySLn3DCCUPEkkQiofd3OwKuXr1aj8mUjjkePWvHgmxqWb5jjLkDr3RfD/AkXrnuNmut5OK1AIfnbZSjgJj7pIlBOmQZP+aYYzj99NMB+MxnPqP7RZRIJBIamuD2tDrQku6mDoJHuGKp6enpUWKRGB/wtwpyUwTdXlrgOX9kgriizmhyYY877jglYHkXbvsed0I8//zzABMqz3UsyEa8mYrXgGE+cBhQAZyT4dCMxlpjzNXGmPXGmIMHswQIUCBkI96cATRba1sBjDG/BJYBNcaYyAC3nwW8m+lka+09wD0D504YL8Zrr70GeA0PhHtXVFRowJVwZ2OMRmm2tbVx1113AYPWHxfRaFRFJRETUqmUiiklJSVqqZHQAjfcIBqNKncvLS3Va8lKsGHDhoMq0iOBm3DitsmRlSgWi+mqJe+iaDg9nliz1BhTbry1V0p1PwMsHzhm3Ep1BwgwUmQj0681xvwCzyyZBF7G49y/AR42xqwY2HZvPgeaL7gu/L1796p8Kxy/srJS0/LcEiKZ8PLLL6tSJxzdWqttckpLS5W7yvVdd79bwsOtlpbLPrhuKT7xCYiXt7e3V+9fUlIy6ezv2SLbUt1fA76WtnkrsCTD4ZMCUlv9/PPPV1EjmUwqscpS3t/frwTqhixkws6dO9m5c+eQ7VLX0iXaT3/60/pdiCsUCmlCSHNzsxLgZZddNoonzAyZdG7NeDedT5iAywwmaq7raHFoTuUAAQ6CQz4M4UAQ5bGiokJFmvb2duX6ru1eGrTdfvvtGRXY4ZCp09+qVasyHutWEBM8+OCDABlXkdGOpaury9cKB7x3Ih7jkpKSnEVsTjQULdHL8l1TU+NrhSMl+MTOv2/fPl9o8sHk3JG440fSNOHVV1/N6rjZs2czf/58wCPadOtMIpFQS0xnZ6cSu4hRpaWlPktSobv+FQqBeBOg6FC0nF5QVlamzYkTiYQGeUkM/O7du5X7LV++XPfLStDb26vWl8cee0yvW8ggrI9+9KMAnHbaacq1e3t7NWHGtc7ISvb222/rsW7ZQBHvDlYKcbIj4PQBig5Fy+nFjLhy5UqVXd3YE1FuTzjhBFXu6uvrlevLObt371aF8MILL2T3bq+H9HPPPQeMnuOHQqGsz3WPc1veCIcXmT4SiWjpkyeeeEK5eSaTpLX2oPH0kxlFS/Svv/667/NASCQSNDY2Al7NdZkAogiXl5cr0U2fPn0IIZWXl2essOA2THYhRLls2TKeeeYZIDPRuYQqE7Srq0uv29XVpYqqG9rgxsBnsioVAwLxJkDRoWg5fbZYv369VhpzzZvCaaPRqC8MWUQKURJPOOEEVZRd/P73vx+yLR6Pq0m0trZWvcaZYuxjsZhuFzPkvn37VNRy2wKJSFZeXq7XP9S8rCNBQPQHgBDtBRdcoHmxbtkQcdy4Dpyamhq1hAhRVVZWUlVVBXgihUyKj3zEa7bulh1pbm7W2PhEIqHNFgSxWEzFH7e/lauTuGVBhNjlHLdSczETfSDeBCg6BJx+GFRVVal40t7ePqT+e39/vyqEr732mlptzj33XMBfyi+TQuoWPa2qqvKV/UtvpGatVe7u1ttxKyG7GVtuqIV8yrEBpw8QoIgQcPoDQLhyLBZTThkOh1U+Fo7rytHbt28f0rG8pKTEV4nMle/lc+PGjYAXjy8N4qy1ypXdvFW32GxTUxMw6HM4//zzfVlabmFZOV90imJGQPQHgIgO7e3tGlnZ19eniqsQVG9vrxKaW+FAxAc3Bj9TrRi3+6G11mepEWKVSRONRjPeSybg6tWrfQWY3P6uci95ruGaThzKCMSbAEWHgNMPgwceeGDYYy6//HLA48zpjdymTZvmq+6bHo/vdkcxxigHr6qqUk7v2tuF07slQgTZcO9iVmAFAdHnAD/+8Y+HbPvVr36V8djPfe5zgF/kEEJ35fhEIqHyfyZCD4fDo2p3c6jF0YwGgXgToOhgCjnzjTGtQBcwui5gY8f0cbx3sd+/EPeea62dMdxBBSV6AGPMemvthwp60wlw72K//3g/u4tAvAlQdAiIPkDRYTyI/p5xuOdEuHex33+8n11RcJk+QIDxRiDeBCg6FIzojTFnG2PeMMZsNsZ8uQD3m22MecYYs8kY8ydjzA0D26cZY35njHlz4HNqHscQNsa8bIx5fOD/+caYtQP3XmWMKcnjvWuMMb8wxrw+8A7+vMDP/sWB9/6aMeanxpjSQj7/wVAQojfGhIHv4TVzWAR8xhizKM+3TQJ/b609GlgKXDtwzy8DTw30ynpq4P984QZgk/N/Ift03Qn81lq7EDh2YBwFefYJ36fMWpv3P+DPgSec/78CfKUQ93bu+SjwUeANYObAtpnAG3m63yw8wjodeBwweM6ZSKZ3kuN7VwPNDOhszvZCPfvhwHa8zpORgec/q1DPP9xfocQbeQmCgvaoMsbMA44D1gL11todAAOfdXm67b8CXwKkKE0thevT1Qi0AisHxKv/NMZUUKBnt9a+A0ifsh3AfiZQn7JCEX2m0L6CmI2MMZXAI8AXrLXtBbrnecBua+2L7uYMh+brHUSADwLft9Yehxf6kXc9SjDWPmX5RqGIvgWY7fx/wB5VuYQxJopH8A9Za385sHmXMWbmwP6ZwO483Pok4BPGmLfwGkyfjsf5a4wxEhqZz3fQArRYa9cO/P8LvElQiGcHp0+ZtTYB+PqUDRxTEBrIhEIR/TpgwYD2XoKn1Pw6nzcc6I91L7DJWvsdZ9ev8XpkQZ56ZVlrv2KtnWWtnYf3rE9bay+hQH26rLU7ge3GmKMGNkmfsLw/+wAmdp+yQikPwMeAJmALcEsB7ncy3vL5KvDHgb+P4cnWTwFvDnxOy/M4TgUeH/jeCLwAbAZ+DsTyeN8PAOsHnn81MLWQzw58HXgdeA14AIgV8vkP9hd4ZAMUHQKPbICiQ0D0AYoOAdEHKDoERB+g6BAQfYCiQ0D0AYoOAdEHKDoERB+g6PD/AXuTo9bSUlyPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df38493550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df387cf668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df4e2314e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df54536518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 96, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1df6fc865f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试数据集输出的正确性\n",
    "itr = enumerate(train_loader)\n",
    "bs, (inputs, targets) = next(itr)\n",
    "inputs, targets = inputs.numpy(), targets.numpy()\n",
    "for index in range(len(inputs)):\n",
    "    input = inputs[index]\n",
    "    print(input.shape)\n",
    "    arr = input.reshape([input.shape[1], input.shape[2]])\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.imshow(arr, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    if index > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRT9Be8cFPcB"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epoch, jump_out_lr=-1.):\n",
    "    # 根据训练的epoch次数来降低learning rate\n",
    "    if epoch >= opt.lrd_se > 0:\n",
    "        frac = ((epoch - opt.lrd_se) // opt.lrd_s) + 1\n",
    "        decay_factor = opt.lrd_r ** frac\n",
    "        current_lr = opt.lr * decay_factor  # current_lr = opt.lr * 降低率 ^ ((epoch - 开始decay的epoch) // 每次decay的epoch num)\n",
    "        utils.set_lr(optimizer, current_lr)  # set the learning rate\n",
    "    else:\n",
    "        current_lr = opt.lr\n",
    "    if epoch < opt.lre_je:\n",
    "        current_lr *= 1.5  # 解决一开始收敛慢的问题\n",
    "    print('learning_rate: %s' % str(current_lr))\n",
    "    global Train_acc\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    cur_train_acc = 0.\n",
    "    time_start = time.time()\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "#         bs, ncrops, c, h, w = np.shape(inputs)\n",
    "#         inputs = inputs.view(-1, c, h, w)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE, torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        outputs = net(inputs)\n",
    "        # print(\"outputs:\", outputs)\n",
    "        # print(\"targets:\", targets)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        utils.clip_gradient(optimizer, 2*current_lr)  # 解决梯度爆炸 https://blog.csdn.net/u010814042/article/details/76154391\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += float(loss.data)\n",
    "        _, predicted = torch.max(outputs.data, 1)  # torch.max() 加上dim参数后，返回值为 max_value, max_value_index\n",
    "        if target_type == 'ls':\n",
    "            ground_value = targets.data\n",
    "        elif target_type == 'fa':\n",
    "            _, ground_value = torch.max(targets.data, 1)\n",
    "        # print(\"predicted:\", predicted)\n",
    "        # print(\"ground_value:\", ground_value)\n",
    "\n",
    "        for i in range(len(predicted)):\n",
    "            if predicted[i] == ground_value[i]:\n",
    "                train_acc_map[predicted[i].item()] += 1\n",
    "\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(ground_value.data).cpu().sum()\n",
    "        # print(\"equal: \", predicted.eq(ground_value.data).cpu())\n",
    "        cur_train_acc = float(correct) / float(total) * 100.\n",
    "\n",
    "        time_end = time.time()\n",
    "        duration = time_end - time_start\n",
    "        utils.progress_bar(batch_idx, len(train_loader), 'Time: %.2fs | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "                           (duration, train_loss / (batch_idx + 1), cur_train_acc, correct, total))\n",
    "\n",
    "        # 删除无用的变量，释放显存\n",
    "        del loss\n",
    "        del inputs\n",
    "        del outputs\n",
    "        del predicted\n",
    "    Train_acc = cur_train_acc\n",
    "    if train_acc_map['best_acc'] < Train_acc:\n",
    "        train_acc_map['best_acc'] = Train_acc\n",
    "        train_acc_map['best_acc_epoch'] = epoch\n",
    "    write_history('Train', epoch, cur_train_acc, train_loss / (batch_idx + 1), None)\n",
    "\n",
    "\n",
    "# Testing\n",
    "def test(epoch):\n",
    "    global Test_acc\n",
    "    private_test_loss = 0\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    cur_test_acc = 0.\n",
    "    correct_map = [0, 0, 0, 0, 0, 0, 0]\n",
    "    time_start = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            bs, c, h, w = np.shape(inputs)\n",
    "#             bs, ncrops, c, h, w = np.shape(inputs)\n",
    "            inputs = inputs.view(-1, c, h, w)\n",
    "            if use_cuda:\n",
    "                inputs, targets = inputs.to(DEVICE), targets.to(DEVICE, torch.long)\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # avg over crops if test_transform contains crop operations\n",
    "            # outputs_avg = outputs.view(bs, ncrops, -1).mean(1)\n",
    "            outputs_avg = outputs\n",
    "\n",
    "            loss = criterion(outputs_avg, targets)\n",
    "            private_test_loss += float(loss.data)\n",
    "            _, predicted = torch.max(outputs_avg.data, 1)\n",
    "            if target_type == 'ls':\n",
    "                ground_value = targets.data\n",
    "            elif target_type == 'fa':\n",
    "                _, ground_value = torch.max(targets.data, 1)\n",
    "\n",
    "            for i in range(len(predicted)):\n",
    "                if predicted[i] == ground_value[i]:\n",
    "                    c = predicted[i].item()\n",
    "                    test_acc_map[c] += 1\n",
    "                    correct_map[c] += 1\n",
    "\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(ground_value.data).cpu().sum()\n",
    "            cur_test_acc = float(correct) / float(total) * 100.\n",
    "\n",
    "            time_end = time.time()\n",
    "            duration = time_end - time_start\n",
    "            utils.progress_bar(batch_idx, len(test_loader), 'Time: %.2fs | Loss: %.3f | Acc: %.3f%% (%d/%d)' %\n",
    "                               (duration, private_test_loss / (batch_idx + 1), cur_test_acc, correct, total))\n",
    "\n",
    "            # 删除无用的变量，释放显存\n",
    "            del loss\n",
    "            del inputs\n",
    "            del outputs\n",
    "            del predicted\n",
    "\n",
    "    Test_acc = cur_test_acc\n",
    "    if test_acc_map['best_acc'] < Test_acc:\n",
    "        test_acc_map['best_acc'] = Test_acc\n",
    "        test_acc_map['best_acc_epoch'] = epoch\n",
    "        print('Saving net to %s' % net_to_save_path)\n",
    "        print('best_acc: %0.3f' % test_acc_map['best_acc'])\n",
    "        print('correct_map: %s' % correct_map)\n",
    "        state = {'net': net.state_dict() if use_cuda else net,\n",
    "                 'best_test_acc': test_acc_map['best_acc'],\n",
    "                 'best_test_acc_epoch': test_acc_map['best_acc_epoch'],\n",
    "                 'cur_epoch': epoch,\n",
    "                 'correct_map': correct_map,\n",
    "                 }\n",
    "        torch.save(state, os.path.join(net_to_save_path, saved_model_name))\n",
    "    write_history('Test', epoch, cur_test_acc, private_test_loss / (batch_idx + 1), correct_map)\n",
    "        \n",
    "\n",
    "def write_history(train_or_test, epoch, acc, loss, predictions):\n",
    "    with open(os.path.join(net_to_save_path, history_file_name), \"a+\", encoding=\"utf-8\") as history_file:\n",
    "        msg = train_or_test + \" %d %.3f %.3f \" % (epoch, acc, loss)\n",
    "        if predictions:\n",
    "            msg += str(predictions)\n",
    "        msg += \"\\n\"\n",
    "        history_file.write(msg)\n",
    "        history_file.flush()\n",
    "\n",
    "def save_over_flag():\n",
    "    file_path = os.path.join(net_to_save_path, model_over_flag_name)\n",
    "    with open(file_path, \"w+\", encoding=\"utf-8\") as file:\n",
    "        file.write(train_acc_map.__str__())\n",
    "        file.write(\"\\n\")\n",
    "        file.write(test_acc_map.__str__())\n",
    "        file.write(\"\\n\")\n",
    "        file.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8228
    },
    "colab_type": "code",
    "id": "VET9IwJvFPcE",
    "outputId": "0d3ecd67-9578-4a19-90bc-06a4d239ac57",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------Epoch: 1214-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.17s | Loss: 1.676 | Acc: 47.020% (426/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.528 | Acc: 37.333% (28/75)\n",
      "\n",
      "------------Epoch: 1215-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.697 | Acc: 47.241% (428/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.540 | Acc: 36.000% (27/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1216-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.697 | Acc: 46.689% (423/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.539 | Acc: 36.000% (27/75)\n",
      "\n",
      "------------Epoch: 1217-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.716 | Acc: 44.481% (403/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.540 | Acc: 36.000% (27/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1218-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.707 | Acc: 44.481% (403/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.541 | Acc: 36.000% (27/75)\n",
      "\n",
      "------------Epoch: 1219-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.704 | Acc: 45.143% (409/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.539 | Acc: 36.000% (27/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1220-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.94s | Loss: 1.703 | Acc: 42.715% (387/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.540 | Acc: 36.000% (27/75)\n",
      "\n",
      "------------Epoch: 1221-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.730 | Acc: 44.812% (406/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.516 | Acc: 40.000% (30/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 40.000\n",
      "correct_map: [6, 0, 0, 3, 0, 0, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1222-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.721 | Acc: 45.143% (409/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.515 | Acc: 40.000% (30/75)\n",
      "\n",
      "------------Epoch: 1223-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.718 | Acc: 44.923% (407/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.539 | Acc: 38.667% (29/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1224-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.709 | Acc: 45.806% (415/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.547 | Acc: 34.667% (26/75)\n",
      "\n",
      "------------Epoch: 1225-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.723 | Acc: 45.033% (408/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.516 | Acc: 40.000% (30/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1226-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.689 | Acc: 46.137% (418/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.517 | Acc: 40.000% (30/75)\n",
      "\n",
      "------------Epoch: 1227-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.715 | Acc: 45.254% (410/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.517 | Acc: 40.000% (30/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1228-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.701 | Acc: 46.137% (418/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.516 | Acc: 40.000% (30/75)\n",
      "\n",
      "------------Epoch: 1229-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.704 | Acc: 46.247% (419/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.517 | Acc: 40.000% (30/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1230-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.702 | Acc: 46.137% (418/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.517 | Acc: 40.000% (30/75)\n",
      "\n",
      "------------Epoch: 1231-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.21s | Loss: 1.710 | Acc: 46.358% (420/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.528 | Acc: 37.333% (28/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1232-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.709 | Acc: 45.916% (416/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.577 | Acc: 36.000% (27/75)\n",
      "\n",
      "------------Epoch: 1233-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.698 | Acc: 46.358% (420/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.516 | Acc: 40.000% (30/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1234-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.688 | Acc: 46.247% (419/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.517 | Acc: 40.000% (30/75)\n",
      "\n",
      "------------Epoch: 1235-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.683 | Acc: 46.799% (424/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.520 | Acc: 38.667% (29/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1236-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.592 | Acc: 56.512% (512/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.454 | Acc: 50.667% (38/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 50.667\n",
      "correct_map: [5, 0, 0, 3, 9, 0, 21]\n",
      "\n",
      "------------Epoch: 1237-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.99s | Loss: 1.558 | Acc: 61.258% (555/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.471 | Acc: 48.000% (36/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1238-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.551 | Acc: 60.706% (550/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.445 | Acc: 52.000% (39/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 52.000\n",
      "correct_map: [6, 0, 0, 0, 12, 0, 21]\n",
      "\n",
      "------------Epoch: 1239-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.562 | Acc: 60.706% (550/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.462 | Acc: 49.333% (37/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1240-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.99s | Loss: 1.553 | Acc: 62.472% (566/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.470 | Acc: 48.000% (36/75)\n",
      "\n",
      "------------Epoch: 1241-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.97s | Loss: 1.537 | Acc: 61.479% (557/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.452 | Acc: 50.667% (38/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1242-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.96s | Loss: 1.528 | Acc: 62.583% (567/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.462 | Acc: 49.333% (37/75)\n",
      "\n",
      "------------Epoch: 1243-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.519 | Acc: 64.349% (583/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.449 | Acc: 52.000% (39/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1244-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.506 | Acc: 64.901% (588/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.442 | Acc: 52.000% (39/75)\n",
      "\n",
      "------------Epoch: 1245-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.508 | Acc: 65.342% (592/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.446 | Acc: 52.000% (39/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1246-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.97s | Loss: 1.500 | Acc: 65.011% (589/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.445 | Acc: 52.000% (39/75)\n",
      "\n",
      "------------Epoch: 1247-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 5.97s | Loss: 1.500 | Acc: 66.115% (599/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.447 | Acc: 52.000% (39/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1248-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.506 | Acc: 65.673% (595/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.448 | Acc: 52.000% (39/75)\n",
      "\n",
      "------------Epoch: 1249-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.503 | Acc: 67.108% (608/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.462 | Acc: 49.333% (37/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1250-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.481 | Acc: 66.777% (605/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.447 | Acc: 52.000% (39/75)\n",
      "\n",
      "------------Epoch: 1251-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.99s | Loss: 1.523 | Acc: 65.563% (594/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.457 | Acc: 49.333% (37/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1252-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.487 | Acc: 66.887% (606/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.446 | Acc: 52.000% (39/75)\n",
      "\n",
      "------------Epoch: 1253-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.485 | Acc: 67.108% (608/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.447 | Acc: 52.000% (39/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1254-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.99s | Loss: 1.480 | Acc: 67.108% (608/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.477 | Acc: 46.667% (35/75)\n",
      "\n",
      "------------Epoch: 1255-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.481 | Acc: 67.219% (609/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.444 | Acc: 52.000% (39/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1256-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.475 | Acc: 68.212% (618/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.414 | Acc: 58.667% (44/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 58.667\n",
      "correct_map: [6, 0, 2, 3, 12, 0, 21]\n",
      "\n",
      "------------Epoch: 1257-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.436 | Acc: 72.296% (655/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.384 | Acc: 62.667% (47/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 62.667\n",
      "correct_map: [6, 0, 12, 0, 8, 0, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1258-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.406 | Acc: 75.166% (681/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.365 | Acc: 65.333% (49/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 65.333\n",
      "correct_map: [0, 0, 18, 0, 10, 0, 21]\n",
      "\n",
      "------------Epoch: 1259-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.418 | Acc: 74.834% (678/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.375 | Acc: 64.000% (48/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1260-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.368 | Acc: 78.918% (715/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.379 | Acc: 64.000% (48/75)\n",
      "\n",
      "------------Epoch: 1261-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.363 | Acc: 79.139% (717/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.328 | Acc: 72.000% (54/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 72.000\n",
      "correct_map: [6, 0, 15, 0, 12, 0, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1262-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.368 | Acc: 80.022% (725/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.332 | Acc: 70.667% (53/75)\n",
      "\n",
      "------------Epoch: 1263-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.376 | Acc: 78.698% (713/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.359 | Acc: 68.000% (51/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1264-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.355 | Acc: 82.450% (747/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.308 | Acc: 76.000% (57/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 76.000\n",
      "correct_map: [6, 0, 18, 0, 12, 0, 21]\n",
      "\n",
      "------------Epoch: 1265-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.339 | Acc: 83.113% (753/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.387 | Acc: 61.333% (46/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1266-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.358 | Acc: 81.015% (734/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.344 | Acc: 69.333% (52/75)\n",
      "\n",
      "------------Epoch: 1267-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.349 | Acc: 81.567% (739/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.328 | Acc: 72.000% (54/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1268-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.342 | Acc: 81.678% (740/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.341 | Acc: 69.333% (52/75)\n",
      "\n",
      "------------Epoch: 1269-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.342 | Acc: 81.788% (741/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.314 | Acc: 74.667% (56/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1270-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.341 | Acc: 83.002% (752/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.352 | Acc: 68.000% (51/75)\n",
      "\n",
      "------------Epoch: 1271-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.27s | Loss: 1.351 | Acc: 81.015% (734/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.326 | Acc: 72.000% (54/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1272-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.311 | Acc: 84.547% (766/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.318 | Acc: 73.333% (55/75)\n",
      "\n",
      "------------Epoch: 1273-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.317 | Acc: 84.547% (766/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.319 | Acc: 73.333% (55/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1274-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.323 | Acc: 84.547% (766/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.340 | Acc: 69.333% (52/75)\n",
      "\n",
      "------------Epoch: 1275-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.318 | Acc: 84.989% (770/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.306 | Acc: 76.000% (57/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1276-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.312 | Acc: 84.989% (770/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.302 | Acc: 76.000% (57/75)\n",
      "\n",
      "------------Epoch: 1277-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.323 | Acc: 84.216% (763/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.307 | Acc: 76.000% (57/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1278-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.339 | Acc: 82.781% (750/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.315 | Acc: 74.667% (56/75)\n",
      "\n",
      "------------Epoch: 1279-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.04s | Loss: 1.345 | Acc: 82.340% (746/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.305 | Acc: 76.000% (57/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1280-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.99s | Loss: 1.334 | Acc: 83.223% (754/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.307 | Acc: 76.000% (57/75)\n",
      "\n",
      "------------Epoch: 1281-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.323 | Acc: 83.775% (759/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.289 | Acc: 78.667% (59/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 78.667\n",
      "correct_map: [5, 0, 18, 3, 12, 0, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1282-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.313 | Acc: 84.768% (768/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.310 | Acc: 76.000% (57/75)\n",
      "\n",
      "------------Epoch: 1283-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.316 | Acc: 84.547% (766/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.304 | Acc: 76.000% (57/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1284-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.318 | Acc: 84.989% (770/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.302 | Acc: 76.000% (57/75)\n",
      "\n",
      "------------Epoch: 1285-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.325 | Acc: 84.879% (769/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.316 | Acc: 74.667% (56/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1286-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.302 | Acc: 85.430% (774/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.315 | Acc: 74.667% (56/75)\n",
      "\n",
      "------------Epoch: 1287-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.321 | Acc: 85.099% (771/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.326 | Acc: 72.000% (54/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1288-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.315 | Acc: 85.099% (771/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.304 | Acc: 77.333% (58/75)\n",
      "\n",
      "------------Epoch: 1289-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.99s | Loss: 1.307 | Acc: 85.541% (775/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.288 | Acc: 78.667% (59/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1290-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.310 | Acc: 85.210% (772/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.310 | Acc: 76.000% (57/75)\n",
      "\n",
      "------------Epoch: 1291-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.302 | Acc: 85.320% (773/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.306 | Acc: 76.000% (57/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1292-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.309 | Acc: 85.430% (774/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.296 | Acc: 78.667% (59/75)\n",
      "\n",
      "------------Epoch: 1293-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.303 | Acc: 85.982% (779/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.298 | Acc: 77.333% (58/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1294-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.296 | Acc: 86.093% (780/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.308 | Acc: 76.000% (57/75)\n",
      "\n",
      "------------Epoch: 1295-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.309 | Acc: 85.872% (778/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.325 | Acc: 73.333% (55/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1296-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.300 | Acc: 85.651% (776/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.307 | Acc: 76.000% (57/75)\n",
      "\n",
      "------------Epoch: 1297-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.303 | Acc: 85.872% (778/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.318 | Acc: 73.333% (55/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1298-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.296 | Acc: 85.982% (779/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.321 | Acc: 73.333% (55/75)\n",
      "\n",
      "------------Epoch: 1299-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.313 | Acc: 85.982% (779/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.327 | Acc: 72.000% (54/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1300-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.301 | Acc: 86.093% (780/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.322 | Acc: 73.333% (55/75)\n",
      "\n",
      "------------Epoch: 1301-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.302 | Acc: 85.872% (778/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.306 | Acc: 74.667% (56/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1302-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.301 | Acc: 85.982% (779/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.308 | Acc: 77.333% (58/75)\n",
      "\n",
      "------------Epoch: 1303-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.300 | Acc: 86.093% (780/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.309 | Acc: 73.333% (55/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1304-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.290 | Acc: 86.534% (784/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.307 | Acc: 74.667% (56/75)\n",
      "\n",
      "------------Epoch: 1305-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.99s | Loss: 1.285 | Acc: 87.528% (793/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.273 | Acc: 81.333% (61/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 81.333\n",
      "correct_map: [5, 0, 18, 3, 12, 2, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1306-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.282 | Acc: 88.300% (800/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.266 | Acc: 82.667% (62/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 82.667\n",
      "correct_map: [5, 0, 18, 3, 9, 6, 21]\n",
      "\n",
      "------------Epoch: 1307-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.256 | Acc: 91.280% (827/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.277 | Acc: 81.333% (61/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1308-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.263 | Acc: 90.618% (821/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.260 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1309-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.246 | Acc: 91.611% (830/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.276 | Acc: 81.333% (61/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1310-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.263 | Acc: 90.287% (818/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.274 | Acc: 81.333% (61/75)\n",
      "\n",
      "------------Epoch: 1311-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.267 | Acc: 89.514% (811/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.282 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1312-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.01s | Loss: 1.259 | Acc: 90.177% (817/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.285 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1313-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.247 | Acc: 91.832% (832/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.278 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1314-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.253 | Acc: 90.839% (823/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.259 | Acc: 84.000% (63/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 84.000\n",
      "correct_map: [6, 0, 18, 0, 12, 6, 21]\n",
      "\n",
      "------------Epoch: 1315-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.244 | Acc: 91.832% (832/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.269 | Acc: 81.333% (61/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1316-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.234 | Acc: 92.715% (840/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1317-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.239 | Acc: 92.936% (842/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.271 | Acc: 82.667% (62/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1318-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.254 | Acc: 91.170% (826/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.296 | Acc: 77.333% (58/75)\n",
      "\n",
      "------------Epoch: 1319-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.244 | Acc: 92.053% (834/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.261 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1320-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.232 | Acc: 93.598% (848/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.257 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1321-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.233 | Acc: 93.377% (846/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.245 | Acc: 86.667% (65/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 86.667\n",
      "correct_map: [6, 0, 18, 2, 12, 6, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1322-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.231 | Acc: 93.046% (843/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.243 | Acc: 86.667% (65/75)\n",
      "\n",
      "------------Epoch: 1323-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.238 | Acc: 92.826% (841/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.278 | Acc: 81.333% (61/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1324-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.247 | Acc: 91.722% (831/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1325-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.229 | Acc: 93.377% (846/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1326-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.230 | Acc: 93.046% (843/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.259 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1327-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.230 | Acc: 93.046% (843/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.236 | Acc: 88.000% (66/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 88.000\n",
      "correct_map: [6, 0, 18, 3, 12, 6, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1328-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.231 | Acc: 93.819% (850/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.274 | Acc: 81.333% (61/75)\n",
      "\n",
      "------------Epoch: 1329-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.240 | Acc: 93.267% (845/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1330-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.248 | Acc: 92.715% (840/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.251 | Acc: 85.333% (64/75)\n",
      "\n",
      "------------Epoch: 1331-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.231 | Acc: 93.709% (849/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.236 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1332-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.226 | Acc: 94.040% (852/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.237 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1333-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.245 | Acc: 92.605% (839/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1334-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.244 | Acc: 92.715% (840/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.246 | Acc: 86.667% (65/75)\n",
      "\n",
      "------------Epoch: 1335-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.240 | Acc: 92.715% (840/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.304 | Acc: 76.000% (57/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1336-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.242 | Acc: 91.611% (830/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1337-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.240 | Acc: 92.715% (840/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.283 | Acc: 78.667% (59/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1338-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.29s | Loss: 1.226 | Acc: 93.598% (848/906)\n",
      "[==============================>] | Time: 0.26s | Loss: 1.282 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1339-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.233 | Acc: 93.377% (846/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.286 | Acc: 78.667% (59/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1340-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.221 | Acc: 94.150% (853/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.283 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1341-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.228 | Acc: 93.929% (851/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.235 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1342-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.230 | Acc: 93.709% (849/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.242 | Acc: 86.667% (65/75)\n",
      "\n",
      "------------Epoch: 1343-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.231 | Acc: 92.936% (842/906)\n",
      "[==============================>] | Time: 0.25s | Loss: 1.292 | Acc: 78.667% (59/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1344-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.238 | Acc: 93.488% (847/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.259 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1345-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.05s | Loss: 1.221 | Acc: 94.040% (852/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1346-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.225 | Acc: 94.260% (854/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.263 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1347-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.226 | Acc: 94.260% (854/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.260 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1348-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.230 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.254 | Acc: 85.333% (64/75)\n",
      "\n",
      "------------Epoch: 1349-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.218 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.252 | Acc: 85.333% (64/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1350-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.220 | Acc: 94.150% (853/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.261 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1351-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.225 | Acc: 94.260% (854/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.293 | Acc: 77.333% (58/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1352-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.236 | Acc: 93.929% (851/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.305 | Acc: 76.000% (57/75)\n",
      "\n",
      "------------Epoch: 1353-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.240 | Acc: 93.267% (845/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.305 | Acc: 76.000% (57/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1354-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.227 | Acc: 93.709% (849/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.294 | Acc: 78.667% (59/75)\n",
      "\n",
      "------------Epoch: 1355-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.234 | Acc: 93.157% (844/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.243 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1356-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.233 | Acc: 93.709% (849/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.269 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1357-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.236 | Acc: 93.157% (844/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.266 | Acc: 82.667% (62/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1358-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.226 | Acc: 93.488% (847/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.282 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1359-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.223 | Acc: 94.040% (852/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.286 | Acc: 78.667% (59/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1360-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.225 | Acc: 93.598% (848/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.299 | Acc: 77.333% (58/75)\n",
      "\n",
      "------------Epoch: 1361-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.218 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.290 | Acc: 77.333% (58/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1362-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.222 | Acc: 94.040% (852/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.296 | Acc: 77.333% (58/75)\n",
      "\n",
      "------------Epoch: 1363-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.217 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.259 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1364-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.217 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.259 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1365-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.216 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.282 | Acc: 78.667% (59/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1366-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.225 | Acc: 94.150% (853/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1367-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.224 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.259 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1368-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.218 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.279 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1369-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.218 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.277 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1370-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.216 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.266 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1371-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.220 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.295 | Acc: 77.333% (58/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1372-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.224 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.259 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1373-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.218 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.268 | Acc: 82.667% (62/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1374-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.217 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.252 | Acc: 85.333% (64/75)\n",
      "\n",
      "------------Epoch: 1375-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.216 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1376-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.223 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.296 | Acc: 77.333% (58/75)\n",
      "\n",
      "------------Epoch: 1377-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.217 | Acc: 94.371% (855/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.284 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1378-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.222 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.292 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1379-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.04s | Loss: 1.215 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.305 | Acc: 76.000% (57/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1380-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.216 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.289 | Acc: 78.667% (59/75)\n",
      "\n",
      "------------Epoch: 1381-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.221 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.274 | Acc: 81.333% (61/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1382-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.235 | Acc: 94.260% (854/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.290 | Acc: 78.667% (59/75)\n",
      "\n",
      "------------Epoch: 1383-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.222 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.276 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1384-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.217 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.264 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1385-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.216 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.282 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1386-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.217 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.282 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1387-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.216 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.273 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1388-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.221 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.265 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1389-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.215 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.254 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1390-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.221 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.246 | Acc: 85.333% (64/75)\n",
      "\n",
      "------------Epoch: 1391-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.215 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.263 | Acc: 82.667% (62/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1392-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.221 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.272 | Acc: 81.333% (61/75)\n",
      "\n",
      "------------Epoch: 1393-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.215 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.259 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1394-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.217 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.280 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1395-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.216 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.274 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1396-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.222 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.267 | Acc: 81.333% (61/75)\n",
      "\n",
      "------------Epoch: 1397-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.220 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.291 | Acc: 77.333% (58/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1398-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.218 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.281 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1399-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.219 | Acc: 94.150% (853/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.288 | Acc: 77.333% (58/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1400-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.215 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.282 | Acc: 78.667% (59/75)\n",
      "\n",
      "------------Epoch: 1401-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.216 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.290 | Acc: 77.333% (58/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1402-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.222 | Acc: 94.481% (856/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.277 | Acc: 81.333% (61/75)\n",
      "\n",
      "------------Epoch: 1403-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.221 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.252 | Acc: 85.333% (64/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1404-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.220 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.268 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1405-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.214 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.257 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1406-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.215 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.257 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1407-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.16s | Loss: 1.215 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.257 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1408-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.220 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.257 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1409-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.00s | Loss: 1.215 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.257 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1410-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.219 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.257 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1411-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.220 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.268 | Acc: 81.333% (61/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1412-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.225 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.263 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1413-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.03s | Loss: 1.220 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.246 | Acc: 85.333% (64/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1414-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.225 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.254 | Acc: 82.667% (62/75)\n",
      "\n",
      "------------Epoch: 1415-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.214 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.253 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1416-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.213 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.248 | Acc: 85.333% (64/75)\n",
      "\n",
      "------------Epoch: 1417-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.213 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.240 | Acc: 86.667% (65/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1418-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.13s | Loss: 1.214 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.248 | Acc: 85.333% (64/75)\n",
      "\n",
      "------------Epoch: 1419-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.218 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1420-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.219 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.267 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1421-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.218 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.270 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1422-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.212 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.268 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1423-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.223 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.266 | Acc: 80.000% (60/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1424-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.217 | Acc: 94.592% (857/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.250 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1425-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.218 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.251 | Acc: 82.667% (62/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1426-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.216 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.249 | Acc: 84.000% (63/75)\n",
      "\n",
      "------------Epoch: 1427-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.215 | Acc: 94.702% (858/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.255 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1428-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.219 | Acc: 94.812% (859/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.258 | Acc: 81.333% (61/75)\n",
      "\n",
      "------------Epoch: 1429-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.212 | Acc: 95.585% (866/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.251 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1430-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.197 | Acc: 96.689% (876/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.237 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1431-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.191 | Acc: 97.572% (884/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.220 | Acc: 92.000% (69/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 92.000\n",
      "correct_map: [6, 9, 18, 0, 12, 3, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1432-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.196 | Acc: 97.792% (886/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.222 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1433-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.182 | Acc: 98.675% (894/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.226 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1434-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.13s | Loss: 1.183 | Acc: 98.675% (894/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.228 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1435-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.184 | Acc: 98.234% (890/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.225 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1436-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.181 | Acc: 98.234% (890/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.219 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1437-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.177 | Acc: 98.896% (896/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.233 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1438-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.194 | Acc: 98.455% (892/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.240 | Acc: 86.667% (65/75)\n",
      "\n",
      "------------Epoch: 1439-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.44s | Loss: 1.204 | Acc: 97.903% (887/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.263 | Acc: 84.000% (63/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1440-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.209 | Acc: 96.247% (872/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.231 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1441-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.183 | Acc: 98.344% (891/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.236 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1442-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.181 | Acc: 98.675% (894/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.252 | Acc: 85.333% (64/75)\n",
      "\n",
      "------------Epoch: 1443-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.182 | Acc: 98.565% (893/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.234 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1444-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.174 | Acc: 99.227% (899/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.237 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1445-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.13s | Loss: 1.186 | Acc: 97.903% (887/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.269 | Acc: 82.667% (62/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1446-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.201 | Acc: 96.578% (875/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.273 | Acc: 80.000% (60/75)\n",
      "\n",
      "------------Epoch: 1447-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.08s | Loss: 1.189 | Acc: 97.572% (884/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.272 | Acc: 86.667% (65/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1448-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.181 | Acc: 98.675% (894/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.243 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1449-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.174 | Acc: 99.338% (900/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.238 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1450-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.175 | Acc: 99.117% (898/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.238 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1451-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.173 | Acc: 99.338% (900/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.239 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1452-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.22s | Loss: 1.175 | Acc: 99.227% (899/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.243 | Acc: 86.667% (65/75)\n",
      "\n",
      "------------Epoch: 1453-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.175 | Acc: 99.007% (897/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.261 | Acc: 86.667% (65/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1454-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.13s | Loss: 1.178 | Acc: 99.117% (898/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.249 | Acc: 85.333% (64/75)\n",
      "\n",
      "------------Epoch: 1455-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.179 | Acc: 98.675% (894/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.238 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1456-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.176 | Acc: 98.896% (896/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.243 | Acc: 86.667% (65/75)\n",
      "\n",
      "------------Epoch: 1457-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.180 | Acc: 98.565% (893/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.233 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1458-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.180 | Acc: 98.455% (892/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.242 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1459-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.178 | Acc: 98.675% (894/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.243 | Acc: 86.667% (65/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1460-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.179 | Acc: 98.675% (894/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.245 | Acc: 86.667% (65/75)\n",
      "\n",
      "------------Epoch: 1461-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.183 | Acc: 98.344% (891/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.238 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1462-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.173 | Acc: 99.338% (900/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.235 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1463-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.175 | Acc: 98.896% (896/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.238 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1464-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.175 | Acc: 99.227% (899/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.221 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1465-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.174 | Acc: 99.227% (899/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.240 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1466-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.22s | Loss: 1.175 | Acc: 99.007% (897/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.239 | Acc: 86.667% (65/75)\n",
      "\n",
      "------------Epoch: 1467-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.246 | Acc: 86.667% (65/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1468-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1469-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.175 | Acc: 99.117% (898/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.212 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1470-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.177 | Acc: 98.675% (894/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1471-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.178 | Acc: 98.896% (896/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1472-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.173 | Acc: 99.227% (899/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.234 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1473-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.173 | Acc: 99.227% (899/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.235 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1474-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.235 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1475-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.175 | Acc: 99.007% (897/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1476-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.234 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1477-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.178 | Acc: 99.338% (900/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.235 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1478-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.180 | Acc: 99.117% (898/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.236 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1479-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.171 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1480-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.227 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1481-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.10s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.212 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1482-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.173 | Acc: 99.227% (899/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.227 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1483-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.170 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1484-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.170 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1485-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1486-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1487-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1488-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.211 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1489-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.176 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1490-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.170 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.210 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1491-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1492-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1493-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.225 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1494-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 93.333% (70/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 93.333\n",
      "correct_map: [6, 9, 18, 1, 12, 3, 21]\n",
      "\n",
      "------------Epoch: 1495-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.216 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1496-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.171 | Acc: 99.338% (900/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.239 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1497-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.175 | Acc: 98.896% (896/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.206 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1498-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1499-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.223 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1500-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.169 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.217 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1501-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1502-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.216 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1503-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1504-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.169 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1505-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1506-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.171 | Acc: 99.227% (899/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.216 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1507-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.229 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1508-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1509-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.169 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1510-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.210 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1511-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.229 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1512-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.218 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1513-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1514-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1515-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.08s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "Saving net to Saved_Models\\5\\CK+_ACCNN_5\n",
      "best_acc: 96.000\n",
      "correct_map: [6, 9, 18, 3, 12, 3, 21]\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1516-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.175 | Acc: 99.007% (897/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.226 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1517-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.175 | Acc: 99.117% (898/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.204 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1518-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.172 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.208 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1519-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.171 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1520-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.228 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1521-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.173 | Acc: 99.338% (900/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.211 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1522-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.169 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1523-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1524-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.205 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1525-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1526-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1527-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.216 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1528-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.171 | Acc: 99.338% (900/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.226 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1529-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.239 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1530-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.173 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.212 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1531-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.174 | Acc: 99.117% (898/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.192 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1532-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.192 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1533-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.169 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1534-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.19s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1535-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.168 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.190 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1536-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.210 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1537-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1538-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.21s | Loss: 1.168 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.204 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1539-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.201 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1540-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.211 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1541-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.13s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.210 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1542-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.24s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.227 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1543-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.16s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.235 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1544-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.23s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.216 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1545-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.212 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1546-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1547-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1548-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.25s | Loss: 1.231 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1549-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1550-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.220 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1551-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.232 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1552-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1553-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1554-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.169 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1555-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.212 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1556-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.203 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1557-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1558-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.205 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1559-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1560-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.192 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1561-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.191 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1562-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.206 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1563-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.204 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1564-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1565-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1566-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1567-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1568-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.191 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1569-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1570-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1571-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.13s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1572-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1573-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1574-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1575-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1576-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.221 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1577-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.221 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1578-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1579-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.211 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1580-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.232 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1581-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.231 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1582-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.168 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1583-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.08s | Loss: 1.169 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.210 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1584-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.176 | Acc: 99.007% (897/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.237 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1585-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.171 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.228 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1586-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.170 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.208 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1587-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.171 | Acc: 99.448% (901/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1588-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.169 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1589-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1590-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.168 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1591-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1592-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1593-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.193 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1594-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.191 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1595-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1596-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1597-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1598-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.193 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1599-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1600-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.169 | Acc: 99.558% (902/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.191 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1601-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1602-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.168 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.190 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1603-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.193 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1604-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1605-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1606-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.204 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1607-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.201 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1608-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1609-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1610-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1611-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.205 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1612-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1613-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1614-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.205 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1615-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.210 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1616-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1617-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.04s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.217 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1618-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1619-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.209 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1620-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.20s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.210 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1621-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.227 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1622-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1623-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.230 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1624-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.217 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1625-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1626-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.206 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1627-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1628-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.193 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1629-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.23s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1630-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.20s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.211 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1631-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.169 | Acc: 99.669% (903/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1632-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.206 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1633-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1634-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1635-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.220 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1636-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.02s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.221 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1637-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.218 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1638-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1639-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.215 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1640-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.224 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1641-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.216 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1642-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.205 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1643-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1644-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1645-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1646-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1647-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.212 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1648-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1649-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.216 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1650-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1651-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1652-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1653-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.229 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1654-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.232 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1655-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.217 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1656-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1657-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1658-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1659-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.209 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1660-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.207 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1661-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1662-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.25s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1663-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1664-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.220 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1665-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.22s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.234 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1666-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.39s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.58s | Loss: 1.234 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1667-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.37s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.229 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1668-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.34s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.217 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1669-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.46s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.211 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1670-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1671-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 5.98s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.219 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1672-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.165 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.225 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1673-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.225 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1674-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.224 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1675-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.50s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1676-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.44s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1677-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.208 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1678-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1679-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.39s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.211 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1680-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.47s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.207 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1681-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.217 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1682-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.05s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1683-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.219 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1684-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.217 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1685-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1686-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.32s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.23s | Loss: 1.216 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1687-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.224 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1688-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.25s | Loss: 1.224 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1689-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.27s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.221 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1690-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.31s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.221 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1691-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1692-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1693-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.211 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1694-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.221 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1695-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.221 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1696-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.217 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1697-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.216 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1698-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1699-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1700-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1701-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.03s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.204 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1702-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.222 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1703-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1704-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.217 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1705-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1706-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.224 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1707-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.231 | Acc: 88.000% (66/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1708-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.230 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1709-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.227 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1710-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.216 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1711-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.211 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1712-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.211 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1713-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.206 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1714-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.202 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1715-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1716-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.206 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1717-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.216 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1718-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.215 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1719-------------\n",
      "learning_rate: 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.212 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1720-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.204 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1721-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1722-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.222 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1723-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.21s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.206 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1724-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.19s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1725-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1726-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1727-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.209 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1728-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.13s | Loss: 1.169 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.233 | Acc: 88.000% (66/75)\n",
      "\n",
      "------------Epoch: 1729-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.09s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.225 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1730-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.222 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1731-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1732-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1733-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1734-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.216 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1735-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1736-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.208 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1737-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.18s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.193 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1738-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.212 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1739-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1740-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.214 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1741-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.207 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1742-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1743-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.22s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1744-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.07s | Loss: 1.167 | Acc: 99.779% (904/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.217 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1745-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.219 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1746-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.201 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1747-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1748-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.01s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.204 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1749-------------\n",
      "learning_rate: 0.01\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1750-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.218 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1751-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.216 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1752-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1753-------------\n",
      "learning_rate: 0.009000000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.217 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1754-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1755-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.221 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1756-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.227 | Acc: 89.333% (67/75)\n",
      "\n",
      "------------Epoch: 1757-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.26s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.226 | Acc: 89.333% (67/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1758-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1759-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.210 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1760-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.25s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1761-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1762-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1763-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.218 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1764-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.01s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.219 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1765-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.217 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1766-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.215 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1767-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.208 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1768-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.209 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1769-------------\n",
      "learning_rate: 0.009000000000000001\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.206 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1770-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1771-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.204 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1772-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.207 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1773-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1774-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1775-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1776-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.199 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1777-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1778-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1779-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1780-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1781-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1782-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1783-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1784-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1785-------------\n",
      "learning_rate: 0.008100000000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.208 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1786-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.206 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1787-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1788-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1789-------------\n",
      "learning_rate: 0.008100000000000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1790-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1791-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.22s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1792-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1793-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1794-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.28s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.198 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1795-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1796-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.23s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1797-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1798-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1799-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1800-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.26s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 92.000% (69/75)\n",
      "\n",
      "------------Epoch: 1801-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.205 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1802-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.49s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1803-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.25s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1804-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1805-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1806-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.19s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1807-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1808-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1809-------------\n",
      "learning_rate: 0.007290000000000001\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1810-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1811-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1812-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.26s | Loss: 1.199 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1813-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1814-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1815-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.16s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1816-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.40s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1817-------------\n",
      "learning_rate: 0.006561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.43s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1818-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.36s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.25s | Loss: 1.207 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1819-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1820-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1821-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.204 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1822-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1823-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1824-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1825-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.205 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1826-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.203 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1827-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1828-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1829-------------\n",
      "learning_rate: 0.006561\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1830-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1831-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1832-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1833-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1834-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.03s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.206 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1835-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.23s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1836-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1837-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.35s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1838-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1839-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.17s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.213 | Acc: 90.667% (68/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1840-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.220 | Acc: 90.667% (68/75)\n",
      "\n",
      "------------Epoch: 1841-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.212 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1842-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.203 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1843-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1844-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.193 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1845-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1846-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1847-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1848-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1849-------------\n",
      "learning_rate: 0.005904900000000001\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1850-------------\n",
      "learning_rate: 0.00531441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1851-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1852-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1853-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1854-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1855-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1856-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1857-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.03s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1858-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1859-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1860-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1861-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1862-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1863-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1864-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.22s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1865-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1866-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.23s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1867-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1868-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1869-------------\n",
      "learning_rate: 0.00531441\n",
      "[==============================>] | Time: 6.27s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1870-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.04s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1871-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1872-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1873-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1874-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1875-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1876-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1877-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.08s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1878-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.204 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1879-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.03s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1880-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.08s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1881-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1882-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1883-------------\n",
      "learning_rate: 0.004782969000000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1884-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.26s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1885-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1886-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1887-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.202 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1888-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1889-------------\n",
      "learning_rate: 0.004782969000000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1890-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.201 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1891-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.202 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1892-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1893-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1894-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1895-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1896-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1897-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1898-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1899-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1900-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.21s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1901-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1902-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1903-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.37s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1904-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1905-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1906-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1907-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1908-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.09s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1909-------------\n",
      "learning_rate: 0.004304672100000001\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1910-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1911-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.21s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1912-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1913-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.26s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1914-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.06s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1915-------------\n",
      "learning_rate: 0.003874204890000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.23s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1916-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.05s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1917-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1918-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1919-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1920-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1921-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.30s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1922-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1923-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1924-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1925-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.167 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1926-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.201 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1927-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1928-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1929-------------\n",
      "learning_rate: 0.003874204890000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1930-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1931-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1932-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1933-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1934-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1935-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1936-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1937-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1938-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1939-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.23s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1940-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.16s | Loss: 1.167 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.208 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1941-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.21s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.210 | Acc: 92.000% (69/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1942-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 99.890% (905/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.208 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1943-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.11s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.204 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1944-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.33s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1945-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.26s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1946-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.25s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1947-------------\n",
      "learning_rate: 0.003486784401000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1948-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1949-------------\n",
      "learning_rate: 0.003486784401000001\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1950-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1951-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1952-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1953-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1954-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1955-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1956-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1957-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1958-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1959-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1960-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1961-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.23s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1962-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1963-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1964-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1965-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1966-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1967-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1968-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1969-------------\n",
      "learning_rate: 0.0031381059609000006\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1970-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1971-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1972-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.20s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.202 | Acc: 93.333% (70/75)\n",
      "\n",
      "------------Epoch: 1973-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1974-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1975-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.26s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1976-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.23s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1977-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1978-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.14s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1979-------------\n",
      "learning_rate: 0.0028242953648100013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================>] | Time: 6.21s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.202 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1980-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.201 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1981-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1982-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1983-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.18s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.198 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1984-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.200 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1985-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.200 | Acc: 93.333% (70/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1986-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1987-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1988-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.21s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1989-------------\n",
      "learning_rate: 0.0028242953648100013\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1990-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.21s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.197 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1991-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.199 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1992-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.13s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1993-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.204 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1994-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.17s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.21s | Loss: 1.202 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1995-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.16s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.22s | Loss: 1.197 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1996-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.12s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.20s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "\n",
      "------------Epoch: 1997-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.10s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.195 | Acc: 96.000% (72/75)\n",
      "Saving Temp Model...\n",
      "\n",
      "------------Epoch: 1998-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.15s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.18s | Loss: 1.194 | Acc: 96.000% (72/75)\n",
      "\n",
      "------------Epoch: 1999-------------\n",
      "learning_rate: 0.002541865828329001\n",
      "[==============================>] | Time: 6.07s | Loss: 1.166 | Acc: 100.000% (906/906)\n",
      "[==============================>] | Time: 0.19s | Loss: 1.196 | Acc: 94.667% (71/75)\n",
      "Saving Temp Model...\n",
      "{'best_acc': 100.0, 'best_acc_epoch': 1524, 0: 100428, 1: 25379, 2: 117623, 3: 54946, 4: 148478, 5: 53635, 6: 178787}\n",
      "{'best_acc': 96.0, 'best_acc_epoch': 1515, 0: 4639, 1: 4809, 2: 13303, 3: 1524, 4: 8420, 5: 2400, 6: 16477}\n",
      "Trained Over\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(net_to_save_dir):\n",
    "    os.mkdir(net_to_save_dir)\n",
    "if not os.path.isdir(os.path.join(net_to_save_dir, str(opt.save_number))):\n",
    "    os.mkdir(os.path.join(net_to_save_dir, str(opt.save_number)))\n",
    "if not os.path.isdir(net_to_save_path):\n",
    "    os.mkdir(net_to_save_path)\n",
    "if not over_flag:\n",
    "    for epoch in range(start_epoch, opt.epoch, 1):\n",
    "        print('\\n------------Epoch: %d-------------' % epoch)\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        temp_internal -= 1\n",
    "        if temp_internal <= 0:\n",
    "            temp_internal = TEMP_EPOCH\n",
    "            print(\"Saving Temp Model...\")\n",
    "            state = {'net': net.state_dict() if use_cuda else net,\n",
    "                 'best_test_acc': test_acc_map['best_acc'],\n",
    "                 'best_test_acc_epoch': test_acc_map['best_acc_epoch'],\n",
    "                 'cur_epoch': epoch,\n",
    "                 }\n",
    "            torch.save(state, os.path.join(net_to_save_path, saved_temp_model_name))\n",
    "    print(train_acc_map)\n",
    "    print(test_acc_map)\n",
    "    save_over_flag()\n",
    "print(\"Trained Over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_test.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
